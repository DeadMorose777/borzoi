{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1602a87d-54e4-400e-8dbc-10aaf5c51bb9",
   "metadata": {},
   "source": [
    "## Импорты и проч"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "271f7532-07ed-462d-8f10-a863315ee1e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-12 18:54:18.151920: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-12 18:54:18.229355: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-03-12 18:54:18.229413: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-03-12 18:54:18.229548: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-12 18:54:18.251963: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-03-12 18:54:19.648435: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# Импортируем необходимые библиотеки и функции\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pysam\n",
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "from baskerville import seqnn, gene as bgene\n",
    "from borzoi_helpers import process_sequence, predict_tracks  # предполагается, что эти функции доступны\n",
    "\n",
    "# Отключаем лишние предупреждения TensorFlow\n",
    "#tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0bcac038-f4bd-4d87-a73f-23d47108ff54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]\n",
      "2.14.0\n",
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2022 NVIDIA Corporation\n",
      "Built on Wed_Sep_21_10:33:58_PDT_2022\n",
      "Cuda compilation tools, release 11.8, V11.8.89\n",
      "Build cuda_11.8.r11.8/compiler.31833905_0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.config.list_physical_devices('GPU'))\n",
    "print(tf.__version__)\n",
    "!nvcc -V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "026b7f71-fe98-430a-a417-415cc9aecfb3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f3c0 model already exists.\n",
      "f3c1 model already exists.\n",
      "f3c2 model already exists.\n",
      "f3c3 model already exists.\n",
      "Gene annotation already exists.\n",
      "Gene annotation (no read-through, protein-coding) already exists.\n",
      "lready exists.n (protein-coding) a\n",
      "TSS annotation already exists.\n",
      "Splice site annotation already exist.\n",
      "Splice site annotation already exist.\n",
      "PolyA site annotation already exist.\n",
      "Human genome FASTA already exists.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "#Download model weights (data fold 3, 4 replicates)\n",
    "for rep in f3c0,f0 f3c1,f1 f3c2,f2 f3c3,f3; do IFS=\",\"; set -- $rep; \n",
    "  mkdir -p \"saved_models/$1/train\"\n",
    "  local_model=\"saved_models/$1/train/model0_best.h5\"\n",
    "  if [ -f \"$local_model\" ]; then\n",
    "    echo \"$1 model already exists.\"\n",
    "  else\n",
    "    wget --progress=bar:force \"https://storage.googleapis.com/seqnn-share/borzoi/$2/model0_best.h5\" -O \"$local_model\"\n",
    "  fi\n",
    "done\n",
    "\n",
    "#Download and uncompress annotation files\n",
    "mkdir -p hg38/genes/gencode41\n",
    "mkdir -p hg38/genes/polyadb\n",
    "\n",
    "if [ -f hg38/genes/gencode41/gencode41_basic_nort.gtf ]; then\n",
    "  echo \"Gene annotation already exists.\"\n",
    "else\n",
    "  wget -O - https://storage.googleapis.com/seqnn-share/helper/gencode41_basic_nort.gtf.gz | gunzip -c > hg38/genes/gencode41/gencode41_basic_nort.gtf\n",
    "fi\n",
    "\n",
    "if [ -f hg38/genes/gencode41/gencode41_basic_nort_protein.gtf ]; then\n",
    "  echo \"Gene annotation (no read-through, protein-coding) already exists.\"\n",
    "else\n",
    "  wget -O - https://storage.googleapis.com/seqnn-share/helper/gencode41_basic_nort_protein.gtf.gz | gunzip -c > hg38/genes/gencode41/gencode41_basic_nort_protein.gtf\n",
    "fi\n",
    "\n",
    "if [ -f hg38/genes/gencode41/gencode41_basic_protein.gtf ]; then\n",
    "  echo \"Gene annotation (protein-coding) already exists.\"\n",
    "else\n",
    "  wget -O - https://storage.googleapis.com/seqnn-share/helper/gencode41_basic_protein.gtf.gz | gunzip -c > hg38/genes/gencode41/gencode41_basic_protein.gtf\n",
    "fi\n",
    "\n",
    "if [ -f hg38/genes/gencode41/gencode41_basic_tss2.bed ]; then\n",
    "  echo \"TSS annotation already exists.\"\n",
    "else\n",
    "  wget -O - https://storage.googleapis.com/seqnn-share/helper/gencode41_basic_tss2.bed.gz | gunzip -c > hg38/genes/gencode41/gencode41_basic_tss2.bed\n",
    "fi\n",
    "\n",
    "if [ -f hg38/genes/gencode41/gencode41_basic_protein_splice.csv.gz ]; then\n",
    "  echo \"Splice site annotation already exist.\"\n",
    "else\n",
    "  wget https://storage.googleapis.com/seqnn-share/helper/gencode41_basic_protein_splice.csv.gz -O hg38/genes/gencode41/gencode41_basic_protein_splice.csv.gz\n",
    "fi\n",
    "\n",
    "if [ -f hg38/genes/gencode41/gencode41_basic_protein_splice.gff ]; then\n",
    "  echo \"Splice site annotation already exist.\"\n",
    "else\n",
    "  wget -O - https://storage.googleapis.com/seqnn-share/helper/gencode41_basic_protein_splice.gff.gz | gunzip -c > hg38/genes/gencode41/gencode41_basic_protein_splice.gff\n",
    "fi\n",
    "\n",
    "if [ -f hg38/genes/polyadb/polyadb_human_v3.csv.gz ]; then\n",
    "  echo \"PolyA site annotation already exist.\"\n",
    "else\n",
    "  wget https://storage.googleapis.com/seqnn-share/helper/polyadb_human_v3.csv.gz -O hg38/genes/polyadb/polyadb_human_v3.csv.gz\n",
    "fi\n",
    "\n",
    "#Download and index hg38 genome\n",
    "mkdir -p hg38/assembly/ucsc\n",
    "\n",
    "if [ -f hg38/assembly/ucsc/hg38.fa ]; then\n",
    "  echo \"Human genome FASTA already exists.\"\n",
    "else\n",
    "  wget -O - http://hgdownload.cse.ucsc.edu/goldenPath/hg38/bigZips/hg38.fa.gz | gunzip -c > hg38/assembly/ucsc/hg38.fa\n",
    "fi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "356f8eaf-d505-4ce8-9e9b-c5b544c50780",
   "metadata": {},
   "source": [
    "## Препроцессинг"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8710eb18-44df-4a87-b730-ef7972fd83e8",
   "metadata": {},
   "source": [
    "Код для понимания какой индекс отвечает за какую клеточную линию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a2dab8c-49cf-4558-876d-bc8151a7e099",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_id</th>\n",
       "      <th>file_path</th>\n",
       "      <th>clip</th>\n",
       "      <th>clip_soft</th>\n",
       "      <th>scale</th>\n",
       "      <th>sum_stat</th>\n",
       "      <th>strand_pair</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>identifier</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>identifier</td>\n",
       "      <td>file</td>\n",
       "      <td>clip</td>\n",
       "      <td>clip_soft</td>\n",
       "      <td>scale</td>\n",
       "      <td>sum_stat</td>\n",
       "      <td>strand_pair</td>\n",
       "      <td>description</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>CNhs10608+</td>\n",
       "      <td>/home/drk/tillage/datasets/human/cage/fantom/C...</td>\n",
       "      <td>768</td>\n",
       "      <td>384</td>\n",
       "      <td>1.0</td>\n",
       "      <td>sum</td>\n",
       "      <td>1</td>\n",
       "      <td>CAGE:Clontech Human Universal Reference Total ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>CNhs10608-</td>\n",
       "      <td>/home/drk/tillage/datasets/human/cage/fantom/C...</td>\n",
       "      <td>768</td>\n",
       "      <td>384</td>\n",
       "      <td>1.0</td>\n",
       "      <td>sum</td>\n",
       "      <td>0</td>\n",
       "      <td>CAGE:Clontech Human Universal Reference Total ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>CNhs10610+</td>\n",
       "      <td>/home/drk/tillage/datasets/human/cage/fantom/C...</td>\n",
       "      <td>768</td>\n",
       "      <td>384</td>\n",
       "      <td>1.0</td>\n",
       "      <td>sum</td>\n",
       "      <td>3</td>\n",
       "      <td>CAGE:SABiosciences XpressRef Human Universal T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>CNhs10610-</td>\n",
       "      <td>/home/drk/tillage/datasets/human/cage/fantom/C...</td>\n",
       "      <td>768</td>\n",
       "      <td>384</td>\n",
       "      <td>1.0</td>\n",
       "      <td>sum</td>\n",
       "      <td>2</td>\n",
       "      <td>CAGE:SABiosciences XpressRef Human Universal T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>CNhs10612+</td>\n",
       "      <td>/home/drk/tillage/datasets/human/cage/fantom/C...</td>\n",
       "      <td>768</td>\n",
       "      <td>384</td>\n",
       "      <td>1.0</td>\n",
       "      <td>sum</td>\n",
       "      <td>5</td>\n",
       "      <td>CAGE:Universal RNA - Human Normal Tissues Bioc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>CNhs10612-</td>\n",
       "      <td>/home/drk/tillage/datasets/human/cage/fantom/C...</td>\n",
       "      <td>768</td>\n",
       "      <td>384</td>\n",
       "      <td>1.0</td>\n",
       "      <td>sum</td>\n",
       "      <td>4</td>\n",
       "      <td>CAGE:Universal RNA - Human Normal Tissues Bioc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6.0</th>\n",
       "      <td>CNhs10615+</td>\n",
       "      <td>/home/drk/tillage/datasets/human/cage/fantom/C...</td>\n",
       "      <td>768</td>\n",
       "      <td>384</td>\n",
       "      <td>1.0</td>\n",
       "      <td>sum</td>\n",
       "      <td>7</td>\n",
       "      <td>CAGE:adipose tissue, adult, pool1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7.0</th>\n",
       "      <td>CNhs10615-</td>\n",
       "      <td>/home/drk/tillage/datasets/human/cage/fantom/C...</td>\n",
       "      <td>768</td>\n",
       "      <td>384</td>\n",
       "      <td>1.0</td>\n",
       "      <td>sum</td>\n",
       "      <td>6</td>\n",
       "      <td>CAGE:adipose tissue, adult, pool1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8.0</th>\n",
       "      <td>CNhs10616+</td>\n",
       "      <td>/home/drk/tillage/datasets/human/cage/fantom/C...</td>\n",
       "      <td>768</td>\n",
       "      <td>384</td>\n",
       "      <td>1.0</td>\n",
       "      <td>sum</td>\n",
       "      <td>9</td>\n",
       "      <td>CAGE:bladder, adult, pool1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               file_id                                          file_path  \\\n",
       "identifier                                                                  \n",
       "NaN         identifier                                               file   \n",
       "0.0         CNhs10608+  /home/drk/tillage/datasets/human/cage/fantom/C...   \n",
       "1.0         CNhs10608-  /home/drk/tillage/datasets/human/cage/fantom/C...   \n",
       "2.0         CNhs10610+  /home/drk/tillage/datasets/human/cage/fantom/C...   \n",
       "3.0         CNhs10610-  /home/drk/tillage/datasets/human/cage/fantom/C...   \n",
       "4.0         CNhs10612+  /home/drk/tillage/datasets/human/cage/fantom/C...   \n",
       "5.0         CNhs10612-  /home/drk/tillage/datasets/human/cage/fantom/C...   \n",
       "6.0         CNhs10615+  /home/drk/tillage/datasets/human/cage/fantom/C...   \n",
       "7.0         CNhs10615-  /home/drk/tillage/datasets/human/cage/fantom/C...   \n",
       "8.0         CNhs10616+  /home/drk/tillage/datasets/human/cage/fantom/C...   \n",
       "\n",
       "            clip  clip_soft  scale  sum_stat  strand_pair  \\\n",
       "identifier                                                  \n",
       "NaN         clip  clip_soft  scale  sum_stat  strand_pair   \n",
       "0.0          768        384    1.0       sum            1   \n",
       "1.0          768        384    1.0       sum            0   \n",
       "2.0          768        384    1.0       sum            3   \n",
       "3.0          768        384    1.0       sum            2   \n",
       "4.0          768        384    1.0       sum            5   \n",
       "5.0          768        384    1.0       sum            4   \n",
       "6.0          768        384    1.0       sum            7   \n",
       "7.0          768        384    1.0       sum            6   \n",
       "8.0          768        384    1.0       sum            9   \n",
       "\n",
       "                                                  description  \n",
       "identifier                                                     \n",
       "NaN                                               description  \n",
       "0.0         CAGE:Clontech Human Universal Reference Total ...  \n",
       "1.0         CAGE:Clontech Human Universal Reference Total ...  \n",
       "2.0         CAGE:SABiosciences XpressRef Human Universal T...  \n",
       "3.0         CAGE:SABiosciences XpressRef Human Universal T...  \n",
       "4.0         CAGE:Universal RNA - Human Normal Tissues Bioc...  \n",
       "5.0         CAGE:Universal RNA - Human Normal Tissues Bioc...  \n",
       "6.0                         CAGE:adipose tissue, adult, pool1  \n",
       "7.0                         CAGE:adipose tissue, adult, pool1  \n",
       "8.0                                CAGE:bladder, adult, pool1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эксперименты, которые подходят (в file_path содержат нужные ID):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_id</th>\n",
       "      <th>file_path</th>\n",
       "      <th>clip</th>\n",
       "      <th>clip_soft</th>\n",
       "      <th>scale</th>\n",
       "      <th>sum_stat</th>\n",
       "      <th>strand_pair</th>\n",
       "      <th>description</th>\n",
       "      <th>local_index</th>\n",
       "      <th>file_name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>identifier</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6396.0</th>\n",
       "      <td>ENCFF905NZB+</td>\n",
       "      <td>/home/drk/tillage/datasets/human/rna/encode/EN...</td>\n",
       "      <td>768</td>\n",
       "      <td>384</td>\n",
       "      <td>0.3</td>\n",
       "      <td>sum_sqrt</td>\n",
       "      <td>6397</td>\n",
       "      <td>RNA:lung tissue female adult (47 years)</td>\n",
       "      <td>0</td>\n",
       "      <td>ENCSR045GTF+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6397.0</th>\n",
       "      <td>ENCFF905NZB-</td>\n",
       "      <td>/home/drk/tillage/datasets/human/rna/encode/EN...</td>\n",
       "      <td>768</td>\n",
       "      <td>384</td>\n",
       "      <td>0.3</td>\n",
       "      <td>sum_sqrt</td>\n",
       "      <td>6396</td>\n",
       "      <td>RNA:lung tissue female adult (47 years)</td>\n",
       "      <td>1</td>\n",
       "      <td>ENCSR045GTF-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6423.0</th>\n",
       "      <td>ENCFF656OUX+</td>\n",
       "      <td>/home/drk/tillage/datasets/human/rna/encode/EN...</td>\n",
       "      <td>768</td>\n",
       "      <td>384</td>\n",
       "      <td>0.3</td>\n",
       "      <td>sum_sqrt</td>\n",
       "      <td>6424</td>\n",
       "      <td>RNA:pancreas tissue female child (16 years)</td>\n",
       "      <td>2</td>\n",
       "      <td>ENCSR071DYD+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6424.0</th>\n",
       "      <td>ENCFF656OUX-</td>\n",
       "      <td>/home/drk/tillage/datasets/human/rna/encode/EN...</td>\n",
       "      <td>768</td>\n",
       "      <td>384</td>\n",
       "      <td>0.3</td>\n",
       "      <td>sum_sqrt</td>\n",
       "      <td>6423</td>\n",
       "      <td>RNA:pancreas tissue female child (16 years)</td>\n",
       "      <td>3</td>\n",
       "      <td>ENCSR071DYD-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6730.0</th>\n",
       "      <td>ENCFF253SBE+</td>\n",
       "      <td>/home/drk/tillage/datasets/human/rna/encode/EN...</td>\n",
       "      <td>768</td>\n",
       "      <td>384</td>\n",
       "      <td>0.3</td>\n",
       "      <td>sum_sqrt</td>\n",
       "      <td>6731</td>\n",
       "      <td>RNA:left lobe of liver tissue male adult (45 y...</td>\n",
       "      <td>4</td>\n",
       "      <td>ENCSR357BYU+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6731.0</th>\n",
       "      <td>ENCFF253SBE-</td>\n",
       "      <td>/home/drk/tillage/datasets/human/rna/encode/EN...</td>\n",
       "      <td>768</td>\n",
       "      <td>384</td>\n",
       "      <td>0.3</td>\n",
       "      <td>sum_sqrt</td>\n",
       "      <td>6730</td>\n",
       "      <td>RNA:left lobe of liver tissue male adult (45 y...</td>\n",
       "      <td>5</td>\n",
       "      <td>ENCSR357BYU-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7240.0</th>\n",
       "      <td>ENCFF133LYJ+</td>\n",
       "      <td>/home/drk/tillage/datasets/human/rna/encode/EN...</td>\n",
       "      <td>768</td>\n",
       "      <td>384</td>\n",
       "      <td>0.3</td>\n",
       "      <td>sum_sqrt</td>\n",
       "      <td>7241</td>\n",
       "      <td>RNA:adrenal gland tissue female adult (41 years)</td>\n",
       "      <td>6</td>\n",
       "      <td>ENCSR763OMY+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7241.0</th>\n",
       "      <td>ENCFF133LYJ-</td>\n",
       "      <td>/home/drk/tillage/datasets/human/rna/encode/EN...</td>\n",
       "      <td>768</td>\n",
       "      <td>384</td>\n",
       "      <td>0.3</td>\n",
       "      <td>sum_sqrt</td>\n",
       "      <td>7240</td>\n",
       "      <td>RNA:adrenal gland tissue female adult (41 years)</td>\n",
       "      <td>7</td>\n",
       "      <td>ENCSR763OMY-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7396.0</th>\n",
       "      <td>ENCFF649RYB+</td>\n",
       "      <td>/home/drk/tillage/datasets/human/rna/encode/EN...</td>\n",
       "      <td>768</td>\n",
       "      <td>384</td>\n",
       "      <td>0.3</td>\n",
       "      <td>sum_sqrt</td>\n",
       "      <td>7397</td>\n",
       "      <td>RNA:kidney tissue female adult (47 years)</td>\n",
       "      <td>8</td>\n",
       "      <td>ENCSR892LBU+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7397.0</th>\n",
       "      <td>ENCFF649RYB-</td>\n",
       "      <td>/home/drk/tillage/datasets/human/rna/encode/EN...</td>\n",
       "      <td>768</td>\n",
       "      <td>384</td>\n",
       "      <td>0.3</td>\n",
       "      <td>sum_sqrt</td>\n",
       "      <td>7396</td>\n",
       "      <td>RNA:kidney tissue female adult (47 years)</td>\n",
       "      <td>9</td>\n",
       "      <td>ENCSR892LBU-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 file_id                                          file_path  \\\n",
       "identifier                                                                    \n",
       "6396.0      ENCFF905NZB+  /home/drk/tillage/datasets/human/rna/encode/EN...   \n",
       "6397.0      ENCFF905NZB-  /home/drk/tillage/datasets/human/rna/encode/EN...   \n",
       "6423.0      ENCFF656OUX+  /home/drk/tillage/datasets/human/rna/encode/EN...   \n",
       "6424.0      ENCFF656OUX-  /home/drk/tillage/datasets/human/rna/encode/EN...   \n",
       "6730.0      ENCFF253SBE+  /home/drk/tillage/datasets/human/rna/encode/EN...   \n",
       "6731.0      ENCFF253SBE-  /home/drk/tillage/datasets/human/rna/encode/EN...   \n",
       "7240.0      ENCFF133LYJ+  /home/drk/tillage/datasets/human/rna/encode/EN...   \n",
       "7241.0      ENCFF133LYJ-  /home/drk/tillage/datasets/human/rna/encode/EN...   \n",
       "7396.0      ENCFF649RYB+  /home/drk/tillage/datasets/human/rna/encode/EN...   \n",
       "7397.0      ENCFF649RYB-  /home/drk/tillage/datasets/human/rna/encode/EN...   \n",
       "\n",
       "           clip clip_soft scale  sum_stat strand_pair  \\\n",
       "identifier                                              \n",
       "6396.0      768       384   0.3  sum_sqrt        6397   \n",
       "6397.0      768       384   0.3  sum_sqrt        6396   \n",
       "6423.0      768       384   0.3  sum_sqrt        6424   \n",
       "6424.0      768       384   0.3  sum_sqrt        6423   \n",
       "6730.0      768       384   0.3  sum_sqrt        6731   \n",
       "6731.0      768       384   0.3  sum_sqrt        6730   \n",
       "7240.0      768       384   0.3  sum_sqrt        7241   \n",
       "7241.0      768       384   0.3  sum_sqrt        7240   \n",
       "7396.0      768       384   0.3  sum_sqrt        7397   \n",
       "7397.0      768       384   0.3  sum_sqrt        7396   \n",
       "\n",
       "                                                  description  local_index  \\\n",
       "identifier                                                                   \n",
       "6396.0                RNA:lung tissue female adult (47 years)            0   \n",
       "6397.0                RNA:lung tissue female adult (47 years)            1   \n",
       "6423.0            RNA:pancreas tissue female child (16 years)            2   \n",
       "6424.0            RNA:pancreas tissue female child (16 years)            3   \n",
       "6730.0      RNA:left lobe of liver tissue male adult (45 y...            4   \n",
       "6731.0      RNA:left lobe of liver tissue male adult (45 y...            5   \n",
       "7240.0       RNA:adrenal gland tissue female adult (41 years)            6   \n",
       "7241.0       RNA:adrenal gland tissue female adult (41 years)            7   \n",
       "7396.0              RNA:kidney tissue female adult (47 years)            8   \n",
       "7397.0              RNA:kidney tissue female adult (47 years)            9   \n",
       "\n",
       "               file_name  \n",
       "identifier                \n",
       "6396.0      ENCSR045GTF+  \n",
       "6397.0      ENCSR045GTF-  \n",
       "6423.0      ENCSR071DYD+  \n",
       "6424.0      ENCSR071DYD-  \n",
       "6730.0      ENCSR357BYU+  \n",
       "6731.0      ENCSR357BYU-  \n",
       "7240.0      ENCSR763OMY+  \n",
       "7241.0      ENCSR763OMY-  \n",
       "7396.0      ENCSR892LBU+  \n",
       "7397.0      ENCSR892LBU-  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Список глобальных индексов (int32) таргетов: [6396 6397 6423 6424 6730 6731 7240 7241 7396 7397]\n"
     ]
    }
   ],
   "source": [
    "# ---  Препроцессинг ---\n",
    "\n",
    "targets_file = 'targets_human.txt'\n",
    "col_names = [\n",
    "    \"identifier\",\n",
    "    \"file_id\",\n",
    "    \"file_path\",\n",
    "    \"clip\",\n",
    "    \"clip_soft\",\n",
    "    \"scale\",\n",
    "    \"sum_stat\",\n",
    "    \"strand_pair\",\n",
    "    \"description\",\n",
    "]\n",
    "\n",
    "targets_df = pd.read_csv(targets_file, sep='\\t', index_col=0, names=col_names)\n",
    "display(targets_df.head(10))\n",
    "\n",
    "# Эксперименты (судя по условию, ищем их в столбце \"file_path\")\n",
    "experiment_ids = [\n",
    "    \"ENCSR892LBU\",\n",
    "    \"ENCSR357BYU\",\n",
    "    \"ENCSR763OMY\",\n",
    "    \"ENCSR071DYD\",\n",
    "    \"ENCSR045GTF\",\n",
    "]\n",
    "\n",
    "def matches_exps(fp):\n",
    "    return any(eid in fp for eid in experiment_ids)\n",
    "\n",
    "filtered_df = targets_df[targets_df['file_path'].apply(matches_exps)].copy()\n",
    "filtered_df['local_index'] = range(len(filtered_df))\n",
    "\n",
    "# Добавляем столбец file_name, который будет извлечён из file_path\n",
    "# Мы добавляем символы + или - в конец, если они присутствуют в file_id\n",
    "filtered_df['file_name'] = filtered_df.apply(\n",
    "    lambda row: f\"{row['file_path'].split('/')[-3]}{row['file_id'][-1]}\" if row['file_id'][-1] in ['+', '-'] else row['file_path'].split(\"/\")[-3],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "print(\"Эксперименты, которые подходят (в file_path содержат нужные ID):\")\n",
    "display(filtered_df)\n",
    "\n",
    "# Собираем список глобальных индексов, потом приводим к int32, чтобы не было float\n",
    "target_index = filtered_df.index.to_numpy(dtype='int32')  # <-- ВАЖНО: dtype='int32'\n",
    "print(\"\\nСписок глобальных индексов (int32) таргетов:\", target_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8695c874-5af3-44f9-8413-5a91f8be2a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6888 строк до мерджа.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Мержим интервалы: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 17/17 [00:00<00:00, 1029.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "После мерджа: 46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chrom</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chr1</td>\n",
       "      <td>143479625</td>\n",
       "      <td>143823752</td>\n",
       "      <td>fold3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chr1</td>\n",
       "      <td>227321006</td>\n",
       "      <td>228550247</td>\n",
       "      <td>fold3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chr11</td>\n",
       "      <td>25440674</td>\n",
       "      <td>48748592</td>\n",
       "      <td>fold3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chr11</td>\n",
       "      <td>48896195</td>\n",
       "      <td>49191149</td>\n",
       "      <td>fold3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chr11</td>\n",
       "      <td>54525074</td>\n",
       "      <td>54820028</td>\n",
       "      <td>fold3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   chrom      start        end   fold\n",
       "0   chr1  143479625  143823752  fold3\n",
       "1   chr1  227321006  228550247  fold3\n",
       "2  chr11   25440674   48748592  fold3\n",
       "3  chr11   48896195   49191149  fold3\n",
       "4  chr11   54525074   54820028  fold3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Получения списка интервалов и их мерж ---\n",
    "\n",
    "import pandas as pd\n",
    "import gzip\n",
    "from tqdm import tqdm\n",
    "\n",
    "bed_file_path = '../data/sequences_human.bed.gz'\n",
    "bed_data = pd.read_csv(\n",
    "    bed_file_path,\n",
    "    sep='\\t',\n",
    "    header=None,\n",
    "    names=[\"chrom\", \"start\", \"end\", \"fold\"],\n",
    "    compression='gzip'\n",
    ")\n",
    "\n",
    "folds_to_process = ['fold3']  # Можно изменить\n",
    "filtered_bed_data = bed_data[ bed_data['fold'].isin(folds_to_process) ]\n",
    "grouped = filtered_bed_data.groupby(\"chrom\")\n",
    "\n",
    "print(len(filtered_bed_data),\"строк до мерджа.\")\n",
    "\n",
    "def merge_intervals(intervals):\n",
    "    intervals.sort(key=lambda x: x[0])\n",
    "    merged = []\n",
    "    for st, en in intervals:\n",
    "        if not merged or st > merged[-1][1]:\n",
    "            merged.append([st, en])\n",
    "        else:\n",
    "            merged[-1][1] = max(merged[-1][1], en)\n",
    "    return merged\n",
    "\n",
    "merged_intervals_list = []\n",
    "unique_chroms = filtered_bed_data['chrom'].nunique()\n",
    "for chrom, group in tqdm(filtered_bed_data.groupby(\"chrom\"), desc=\"Мержим интервалы\", total=unique_chroms):\n",
    "    intervals = group[['start','end']].values.tolist()\n",
    "    merged = merge_intervals(intervals)\n",
    "    fold_val = group['fold'].iloc[0]\n",
    "    for st, en in merged:\n",
    "        merged_intervals_list.append({'chrom': chrom, 'start': st, 'end': en, 'fold': fold_val})\n",
    "\n",
    "filtered_bed_data = pd.DataFrame(merged_intervals_list)\n",
    "print(\"После мерджа:\", len(filtered_bed_data))\n",
    "display(filtered_bed_data.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d775e26-5708-40d5-af32-fa13b6c8ba89",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Проверка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6d5dbf-18d6-4aff-a9c8-de8b5757820f",
   "metadata": {},
   "source": [
    "Убедимся что все записи влезут во входящее окно модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1871339-b2e9-400f-b396-42220742d447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Максимальная длина последовательности: 67957002 нуклеотидов\n"
     ]
    }
   ],
   "source": [
    "# Находим максимальную длину последовательности\n",
    "max_sequence_length = 0\n",
    "\n",
    "for index, row in filtered_bed_data.iterrows():\n",
    "    start = row['start']\n",
    "    end = row['end']\n",
    "    \n",
    "    # Вычисляем длину текущей последовательности\n",
    "    sequence_length = end - start\n",
    "    \n",
    "    # Обновляем максимальную длину, если текущая больше\n",
    "    if sequence_length > max_sequence_length:\n",
    "        max_sequence_length = sequence_length\n",
    "\n",
    "print(f\"Максимальная длина последовательности: {max_sequence_length} нуклеотидов\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f98bc5-6983-463d-aad5-37a9d8d37ab3",
   "metadata": {},
   "source": [
    "Проверка на пересечения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50821f49-ce28-4efa-8a56-522b05a40531",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking for overlaps: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 17/17 [00:00<00:00, 1105.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Пересечений не обнаружено в filtered_bed_data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "overlap_found = False\n",
    "\n",
    "# Получаем список уникальных хромосом\n",
    "chromosomes = filtered_bed_data['chrom'].unique()\n",
    "\n",
    "# Используем tqdm для отображения прогресса\n",
    "for chrom in tqdm(chromosomes, desc=\"Checking for overlaps\"):\n",
    "    # Фильтруем по текущей хромосоме\n",
    "    group = filtered_bed_data[filtered_bed_data['chrom'] == chrom]\n",
    "    \n",
    "    # Сортируем записи по старту\n",
    "    sorted_group = group.sort_values('start')\n",
    "    \n",
    "    # Инициализируем предыдущую запись\n",
    "    prev_row = None\n",
    "    \n",
    "    # Проходим по отсортированным записям\n",
    "    for idx, row in sorted_group.iterrows():\n",
    "        if prev_row is not None:\n",
    "            # Проверяем пересечение\n",
    "            if row['start'] < prev_row['end']:\n",
    "                print(f\"Пересечение на {chrom}: {prev_row[['start', 'end']].to_dict()} и {row[['start', 'end']].to_dict()}\")\n",
    "                overlap_found = True\n",
    "        prev_row = row\n",
    "\n",
    "if not overlap_found:\n",
    "    print(\"Пересечений не обнаружено в filtered_bed_data.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "484758a2-709d-4f14-b2f9-86219a181aa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Уникальные хромосомы в выборке:\n",
      "['chr5' 'chr11' 'chr6' 'chr9' 'chr13' 'chr2' 'chr8' 'chr7' 'chr17' 'chrX'\n",
      " 'chr18' 'chr12' 'chr15' 'chr19' 'chr1' 'chr16' 'chr20']\n",
      "Количество уникальных хромосом: 17\n",
      "\n",
      "Минимальный start и максимальный end по хромосомам:\n",
      "       min_start    max_end\n",
      "chrom                      \n",
      "chr1   143479625  228550247\n",
      "chr11   25440674   56541083\n",
      "chr12   32992234   34368994\n",
      "chr13   40653298  102135774\n",
      "chr15   20168638   34675550\n",
      "chr16   33491584   33884884\n",
      "chr17   81799133   83225066\n",
      "chr18   13485786   15206757\n",
      "chr19    3108622    9156817\n",
      "chr2    68747521  129505661\n",
      "chr20   30186694   30383302\n",
      "chr5     8770274  103148800\n",
      "chr6    99603327  170690035\n",
      "chr7       10000   74778699\n",
      "chr8     8158857   55824055\n",
      "chr9    80588528  138217638\n",
      "chrX     3230043   58109050\n",
      "\n",
      "Выборка содержит более одной хромосомы.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import gzip\n",
    "\n",
    "# Загрузим данные из bed-файла\n",
    "bed_file_path = '../data/sequences_human.bed.gz'\n",
    "with gzip.open(bed_file_path, 'rt') as file:\n",
    "    bed_data = pd.read_csv(file, sep='\\t', header=None, \n",
    "                           names=[\"chrom\", \"start\", \"end\", \"fold\"])\n",
    "\n",
    "# Фильтруем данные по fold3 и fold4\n",
    "#folds_to_process = ['fold3', 'fold4']\n",
    "folds_to_process = ['fold3']\n",
    "filtered_bed_data = bed_data[bed_data['fold'].isin(folds_to_process)]\n",
    "\n",
    "# Выведем список уникальных хромосом\n",
    "unique_chroms = filtered_bed_data['chrom'].unique()\n",
    "print(\"Уникальные хромосомы в выборке:\")\n",
    "print(unique_chroms)\n",
    "print(f\"Количество уникальных хромосом: {len(unique_chroms)}\")\n",
    "\n",
    "# Для каждой хромосомы находим минимальный start и максимальный end\n",
    "chrom_stats = filtered_bed_data.groupby(\"chrom\").agg(min_start=('start', 'min'),\n",
    "                                                      max_end=('end', 'max'))\n",
    "print(\"\\nМинимальный start и максимальный end по хромосомам:\")\n",
    "print(chrom_stats)\n",
    "\n",
    "if len(unique_chroms) > 1:\n",
    "    print(\"\\nВыборка содержит более одной хромосомы.\")\n",
    "else:\n",
    "    print(\"\\nВыборка содержит только одну хромосому.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f758c39f-4ea0-4315-ba25-88035f51f983",
   "metadata": {},
   "source": [
    "## Модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8861ef2c-9185-4c8e-9011-b591d8e08535",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-12 18:54:39.379792: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 23390 MB memory:  -> device: 0, name: Tesla V100-PCIE-32GB, pci bus id: 0000:21:01.0, compute capability: 7.0\n",
      "2025-03-12 18:54:39.380519: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 30965 MB memory:  -> device: 1, name: Tesla V100-PCIE-32GB, pci bus id: 0000:21:02.0, compute capability: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Загружено 4 моделей, каждая со срезом по 10 каналам.\n",
      "Параметры первой модели:\n",
      " stride = 32 crop = 16 tlen = 16352\n"
     ]
    }
   ],
   "source": [
    "# --- ЯЧЕЙКА 5: Инициализация моделей (n_reps) ---\n",
    "\n",
    "params_file = 'params_pred.json'\n",
    "with open(params_file) as f:\n",
    "    params = json.load(f)\n",
    "params_model = params['model']\n",
    "params_train = params['train']\n",
    "\n",
    "# ВАЖНО: n_reps > 1 => несколько реплик\n",
    "n_reps = 4  # или 1, если хотим 1\n",
    "rc = False  # мы не усредняем rc, т.к. +/– цепи разные каналы\n",
    "# Папки: f3c0, f3c1, f3c2, f3c3\n",
    "\n",
    "models = []\n",
    "for rep_ix in range(n_reps):\n",
    "    model_file = f\"saved_models/f3c{rep_ix}/train/model0_best.h5\"\n",
    "\n",
    "    seqnn_model = seqnn.SeqNN(params_model)\n",
    "    seqnn_model.restore(model_file, 0)\n",
    "\n",
    "    # Используем build_slice(...) по target_index (из ЯЧЕЙКИ 2)\n",
    "    seqnn_model.build_slice(target_index)\n",
    "\n",
    "    # build_ensemble\n",
    "    seqnn_model.build_ensemble(rc, [0])\n",
    "    \n",
    "    models.append(seqnn_model)\n",
    "\n",
    "print(f\"Загружено {n_reps} моделей, каждая со срезом по {len(target_index)} каналам.\")\n",
    "print(\"Параметры первой модели:\")\n",
    "print(\" stride =\", models[0].model_strides[0],\n",
    "      \"crop =\", models[0].target_crops[0],\n",
    "      \"tlen =\", models[0].target_lengths[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f1fac8c-f4b6-4435-8ca2-30f65022126a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Model Summary ===\n",
      "Model: \"model_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " sequence (InputLayer)       [(None, 524288, 4)]       0         \n",
      "                                                                 \n",
      " model_13 (Functional)       (None, 16352, 7611)       185917723 \n",
      "                                                                 \n",
      " tf.compat.v1.gather_3 (TFO  (None, 16352, 10)         0         \n",
      " pLambda)                                                        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 185917723 (709.22 MB)\n",
      "Trainable params: 185892699 (709.12 MB)\n",
      "Non-trainable params: 25024 (97.75 KB)\n",
      "_________________________________________________________________\n",
      "\n",
      "=== Model Parameters ===\n",
      "stride         = 32\n",
      "crop           = 16\n",
      "target_length  = 16352\n",
      "\n",
      "Dummy sequence shape: (524288, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-22 03:03:47.550035: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8902\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Raw Prediction Output (прямая цепь) ===\n",
      "dummy_pred.shape = (1, 1, 16352, 10)\n",
      "После индексирования y_plus.shape = (1, 10)\n",
      "\n",
      "=== Raw Prediction Output (реверс-компл.) ===\n",
      "dummy_pred_rc.shape = (1, 1, 16352, 10)\n",
      "После индексирования y_minus.shape = (1, 10)\n",
      "\n",
      "=== Примеры статистики выходного тензора ===\n",
      "Прямая цепь: min = 0.005516 max = 0.02629\n",
      "Реверс цепь: min = 0.012474 max = 0.05438\n"
     ]
    }
   ],
   "source": [
    "def debug_model(model, seq_len=524288):\n",
    "    \"\"\"\n",
    "    Отладочная функция для проверки работы модели.\n",
    "    Выводит:\n",
    "      - модельную сводку (summary)\n",
    "      - ключевые параметры: stride, crop, target_length\n",
    "      - форму входного (dummy) массива\n",
    "      - форму выходных предсказаний (для прямой и реверс-комплементарной последовательностей)\n",
    "    \"\"\"\n",
    "    print(\"=== Model Summary ===\")\n",
    "    model.model.summary()\n",
    "    \n",
    "    print(\"\\n=== Model Parameters ===\")\n",
    "    print(f\"stride         = {model.model_strides[0]}\")\n",
    "    print(f\"crop           = {model.target_crops[0]}\")\n",
    "    print(f\"target_length  = {model.target_lengths[0]}\")\n",
    "    \n",
    "    # Создадим dummy one-hot последовательность\n",
    "    # Каждая строка будет ровно одной единицей на 4 элементах.\n",
    "    dummy_seq = np.zeros((seq_len, 4), dtype=np.float32)\n",
    "    for i in range(seq_len):\n",
    "        dummy_seq[i, np.random.randint(0, 4)] = 1.0\n",
    "    print(\"\\nDummy sequence shape:\", dummy_seq.shape)\n",
    "    \n",
    "    # Предсказание для прямой цепи\n",
    "    dummy_pred = predict_tracks([model], dummy_seq)\n",
    "    print(\"\\n=== Raw Prediction Output (прямая цепь) ===\")\n",
    "    print(\"dummy_pred.shape =\", dummy_pred.shape)\n",
    "    # Ожидается форма вроде: [1, L_out, X, C]. Попробуем взять replicate=0 и strand=0:\n",
    "    try:\n",
    "        y_plus = dummy_pred[0, :, 0, :]\n",
    "        print(\"После индексирования y_plus.shape =\", y_plus.shape)\n",
    "    except Exception as e:\n",
    "        print(\"Ошибка индексирования y_plus:\", e)\n",
    "    \n",
    "    # Предсказание для реверс-комплементарного входа\n",
    "    def reverse_complement_onehot(seq_onehot):\n",
    "        rev = np.flip(seq_onehot, axis=0)\n",
    "        revcomp = rev[:, [3,2,1,0]]\n",
    "        return revcomp\n",
    "\n",
    "    dummy_seq_rc = reverse_complement_onehot(dummy_seq)\n",
    "    dummy_pred_rc = predict_tracks([model], dummy_seq_rc)\n",
    "    print(\"\\n=== Raw Prediction Output (реверс-компл.) ===\")\n",
    "    print(\"dummy_pred_rc.shape =\", dummy_pred_rc.shape)\n",
    "    try:\n",
    "        y_minus = dummy_pred_rc[0, :, 0, :]\n",
    "        print(\"После индексирования y_minus.shape =\", y_minus.shape)\n",
    "    except Exception as e:\n",
    "        print(\"Ошибка индексирования y_minus:\", e)\n",
    "    \n",
    "    # Можно вывести также максимальные и минимальные значения предсказания\n",
    "    print(\"\\n=== Примеры статистики выходного тензора ===\")\n",
    "    print(\"Прямая цепь: min =\", np.min(y_plus), \"max =\", np.max(y_plus))\n",
    "    print(\"Реверс цепь: min =\", np.min(y_minus), \"max =\", np.max(y_minus))\n",
    "\n",
    "\n",
    "# Запускаем отладку модели:\n",
    "debug_model(seqnn_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6bb2fe65-88bc-448d-9a3c-1479dc26a168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Пример chr_sizes: [('chr1', 248956422), ('chr10', 133797422), ('chr11', 135086622)]\n"
     ]
    }
   ],
   "source": [
    "# --- ЯЧЕЙКА 6: Загрузка FASTA, chr_sizes ---\n",
    "\n",
    "fasta_path = \"hg38/assembly/ucsc/hg38.fa\"\n",
    "fasta_index = pysam.Fastafile(fasta_path)\n",
    "chr_sizes = {c: fasta_index.get_reference_length(c) for c in fasta_index.references}\n",
    "print(\"Пример chr_sizes:\", list(chr_sizes.items())[:3])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70cfab9c-871c-4cfc-89cb-540d2ae9721e",
   "metadata": {},
   "source": [
    "## Инференс"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7de044f1-8a87-4cbe-ba57-371c53189a13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Всего сформировано 1785 окон.\n"
     ]
    }
   ],
   "source": [
    "# --- Формирование окон ---\n",
    "\n",
    "center_len = 196_608\n",
    "context_len = 163_840\n",
    "\n",
    "all_windows = []\n",
    "for _, row in filtered_bed_data.iterrows():\n",
    "    chrom = row['chrom']\n",
    "    st_merged = row['start']\n",
    "    en_merged = row['end']\n",
    "    curr_start = st_merged\n",
    "    while curr_start < en_merged:\n",
    "        curr_end = curr_start + center_len\n",
    "        if curr_end > en_merged:\n",
    "            curr_end = en_merged\n",
    "        all_windows.append((chrom, curr_start, curr_end))\n",
    "        curr_start = curr_end\n",
    "\n",
    "print(\"Всего сформировано\", len(all_windows), \"окон.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ded98b6a-080f-4981-9bc8-1e4740a552fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- обратная трансформация ---\n",
    "\n",
    "def inverse_transform(y_array, clip, clip_soft, scale, sum_stat):\n",
    "    \"\"\"\n",
    "    Упрощённая логика «обратной» трансформации:\n",
    "    1) Делим на scale (если scale != 1)\n",
    "    2) Если sum_stat='sum_sqrt', снимаем clip_soft и sqrt\n",
    "       (как в примере: y->(y-clip_soft+1)**2 + clip_soft -1, потом (y+1)**2 -1)\n",
    "       иначе ничего не делаем.\n",
    "    \"\"\"\n",
    "    # Преобразуем входные параметры к float,\n",
    "    # чтобы избежать TypeError при делении (например, если они считались строками).\n",
    "    clip = float(clip) if clip is not None else 0.0\n",
    "    clip_soft = float(clip_soft) if clip_soft is not None else 0.0\n",
    "    scale = float(scale) if scale is not None else 1.0\n",
    "\n",
    "    # Переводим sum_stat в нижний регистр на всякий случай\n",
    "    if isinstance(sum_stat, str):\n",
    "        sum_stat = sum_stat.lower()\n",
    "    else:\n",
    "        sum_stat = \"\"\n",
    "\n",
    "    # Копируем массив в float32\n",
    "    y = np.array(y_array, dtype=np.float32)\n",
    "\n",
    "    # 1) Делим на scale\n",
    "    if scale != 1.0:\n",
    "        y /= scale\n",
    "\n",
    "    # 2) Если sum_stat='sum_sqrt', снимаем clip_soft + sqrt\n",
    "    if sum_stat == 'sum_sqrt':\n",
    "        if clip_soft > 0:\n",
    "            # (y - clip_soft +1)**2 + clip_soft -1\n",
    "            y_unclip = (y - clip_soft + 1.0)**2 + clip_soft - 1.0\n",
    "            mask = (y > clip_soft)\n",
    "            y[mask] = y_unclip[mask]\n",
    "        # Далее снимаем sqrt+1 => (y+1)**2 -1 (упрощённая логика)\n",
    "        y = (y + 1.0)**2 - 1.0\n",
    "\n",
    "    return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7972a3d-f1be-4e14-a624-7b8089ce1082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Логика обработки входных данных для отрицательных цепей ---\n",
    "\n",
    "def reverse_complement_onehot(seq_onehot):\n",
    "    \"\"\"\n",
    "    Преобразует (L,4) → (L,4) реверс-комплемент с реверсированием.\n",
    "    \"\"\"\n",
    "    rev = np.flip(seq_onehot, axis=0)  # Реверсируем последовательность\n",
    "    revcomp = rev[:, [3, 2, 1, 0]]    # Меняем на комплементарные основания\n",
    "    return revcomp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "455f01db-fdab-4b75-9366-94c1b0295815",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Инференс с обратной трансформацией для + и - цепей (2 варианта: forward и reverse) ---\n",
    "folds_str = \"_\".join(folds_to_process) \n",
    "\n",
    "def run_inference(all_windows, models):\n",
    "    \"\"\"\n",
    "    Для каждого окна (chrom, cstart, cend) делаем 2 варианта:\n",
    "     - forward: обычный вход\n",
    "     - reverse: реверс-комплемент вход, с последующим обратным реверсированием выходов\n",
    "    и записываем результаты (после обратной трансформации) в 2 отдельных файла на канал:\n",
    "     borzoi_rnaseq_{folds_str}_{file_id}_fw.bedGraph\n",
    "     borzoi_rnaseq_{folds_str}_{file_id}_rc.bedGraph\n",
    "\n",
    "    При записи добавляется ручной сдвиг на 512 баз ( pos_start += 512 ).\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    print(f\"Старт инференса (2 варианта) по {len(all_windows)} окнам.\")\n",
    "\n",
    "    stride = models[0].model_strides[0]\n",
    "    crop   = models[0].target_crops[0]\n",
    "    SHIFT  = 512  # ручной сдвиг координат\n",
    "\n",
    "    def write_bedgraph(chrom, cstart, cend, values, file_name, suffix_label):\n",
    "        \"\"\"\n",
    "        Записываем массив values в файл \n",
    "          borzoi_rnaseq_{folds_str}_{file_name}_{suffix_label}.bedGraph,\n",
    "        учитывая смещение SHIFT.\n",
    "        \"\"\"\n",
    "        bed_path = os.path.join(output_dir, f\"borzoi_rnaseq_{folds_str}_{file_name}_{suffix_label}.bedGraph\")\n",
    "        for i, val in enumerate(values):\n",
    "            pos_start = cstart + i * stride + SHIFT\n",
    "            pos_end   = pos_start + stride\n",
    "            if pos_end > cend + SHIFT:\n",
    "                pos_end = cend + SHIFT\n",
    "            if pos_end <= pos_start:\n",
    "                break\n",
    "            with open(bed_path, \"a\") as f_bg:\n",
    "                f_bg.write(f\"{chrom}\\t{pos_start}\\t{pos_end}\\t{float(val)}\\n\")\n",
    "\n",
    "    for (chrom, cstart, cend) in tqdm(all_windows, desc=\"Inference windows\"):\n",
    "        # 1) Формируем входные данные\n",
    "        input_start = max(0, cstart - context_len)\n",
    "        input_end   = min(chr_sizes[chrom], cend + context_len)\n",
    "\n",
    "        seq_1hot = process_sequence(fasta_index, chrom, input_start, input_end)\n",
    "        if seq_1hot is None or seq_1hot.shape[0] == 0:\n",
    "            continue\n",
    "\n",
    "        # 2) Предсказание для forward входа\n",
    "        y_pred_fw = predict_tracks(models, seq_1hot)[0, 0, :, :]  # [L_out, C]\n",
    "\n",
    "        # 3) Предсказание для reverse входа: сначала преобразуем вход,\n",
    "        # затем получаем предсказание и после этого переворачиваем выход по оси 0\n",
    "        seq_rc = reverse_complement_onehot(seq_1hot)\n",
    "        y_pred_rc = predict_tracks(models, seq_rc)[0, 0, :, :]  # [L_out, C]\n",
    "        y_pred_rc = np.flip(y_pred_rc, axis=0)\n",
    "\n",
    "        L_out = y_pred_fw.shape[0]\n",
    "\n",
    "        # 4) Определяем, какой кусок из предсказания соответствует [cstart, cend]\n",
    "        offset_nt = stride * crop\n",
    "        out_start_nt = offset_nt\n",
    "        out_end_nt = offset_nt + stride * (L_out - 2 * crop)\n",
    "\n",
    "        center_start_in_input = cstart - input_start\n",
    "        center_end_in_input = cend - input_start\n",
    "\n",
    "        slice_start_nt = max(center_start_in_input, out_start_nt)\n",
    "        slice_end_nt = min(center_end_in_input, out_end_nt)\n",
    "        if slice_end_nt <= slice_start_nt:\n",
    "            continue\n",
    "\n",
    "        out_slice_start = int((slice_start_nt - out_start_nt) // stride)\n",
    "        out_slice_end = int(np.ceil((slice_end_nt - out_start_nt) / stride))\n",
    "\n",
    "        if out_slice_start < 0:\n",
    "            out_slice_start = 0\n",
    "        if out_slice_end > (L_out - 2 * crop):\n",
    "            out_slice_end = L_out - 2 * crop\n",
    "        if out_slice_end <= out_slice_start:\n",
    "            continue\n",
    "\n",
    "        out_slice_start_full = crop + out_slice_start\n",
    "        out_slice_end_full = crop + out_slice_end\n",
    "\n",
    "        # 5) Выделяем нужные предсказания для forward и reverse вариантов\n",
    "        pred_fw_slice = y_pred_fw[out_slice_start_full:out_slice_end_full, :]\n",
    "        pred_rc_slice = y_pred_rc[out_slice_start_full:out_slice_end_full, :]\n",
    "\n",
    "        length_slice = pred_fw_slice.shape[0]\n",
    "        if length_slice <= 0:\n",
    "            continue\n",
    "\n",
    "        # 6) Для каждого канала делаем обратную трансформацию и записываем в соответствующие bedGraph файлы\n",
    "        for channel_ix in range(pred_fw_slice.shape[1]):\n",
    "            global_id = target_index[channel_ix]\n",
    "            row = targets_df.loc[global_id]\n",
    "            clip_val = row['clip']\n",
    "            clip_soft_val = row['clip_soft']\n",
    "            scale_val = row['scale']\n",
    "            sum_stat_val = row['sum_stat']\n",
    "            file_path = row['file_path']\n",
    "\n",
    "            # Формируем правильное название файла из file_path\n",
    "            experiment_name = file_path.split(\"/\")[-3]\n",
    "            if row['file_id'][-1] in ['+', '-']:\n",
    "                file_name = f\"{experiment_name}{row['file_id'][-1]}\"\n",
    "            else:\n",
    "                file_name = experiment_name\n",
    "\n",
    "            vals_fw = inverse_transform(pred_fw_slice[:, channel_ix], clip_val, clip_soft_val, scale_val, sum_stat_val)\n",
    "            vals_rc = inverse_transform(pred_rc_slice[:, channel_ix], clip_val, clip_soft_val, scale_val, sum_stat_val)\n",
    "\n",
    "            write_bedgraph(chrom, cstart, cend, vals_fw, file_name, \"fw\")\n",
    "            write_bedgraph(chrom, cstart, cend, vals_rc, file_name, \"rc\")\n",
    "\n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"Инференс завершён за {elapsed:.2f} секунд.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2112a1-8aa0-42b0-8144-2ff3e941cdab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start inference...\n",
      "Старт инференса (2 варианта) по 1785 окнам.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference windows:   1%|▋                                                                                                                            | 9/1785 [01:18<4:12:24,  8.53s/it]"
     ]
    }
   ],
   "source": [
    "print(\"Start inference...\")\n",
    "run_inference(all_windows, models)\n",
    "print(\"Done. BedGraph files have been saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6cb7e6a-39e4-4bc6-b75d-caabe3602fa1",
   "metadata": {},
   "source": [
    "## Пост процесс"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2c93effb-ac61-49d5-b4ae-07d397b1dd2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Сдвиг координат на 512 баз завершен.\n"
     ]
    }
   ],
   "source": [
    "# ---  Пост-процессинг записанных bedGraph файлов (сдвиг координат) ---\n",
    "# Не обязательная вещь, просто если предикты не попадают в гены можно легко дофиксить бегграфы этой ячейкой\n",
    "\n",
    "import os\n",
    "\n",
    "def shift_bedgraph_files(output_dir, shift=512):\n",
    "    \"\"\"\n",
    "    Пост-процессинг: откроет все bedGraph файлы в output_dir и сдвигет их координаты на `shift` баз.\n",
    "    \"\"\"\n",
    "    for file_name in os.listdir(output_dir):\n",
    "        if file_name.endswith(\".bedGraph\"):\n",
    "            file_path = os.path.join(output_dir, file_name)\n",
    "            \n",
    "            with open(file_path, 'r') as f:\n",
    "                lines = f.readlines()\n",
    "\n",
    "            with open(file_path, 'w') as f:\n",
    "                for line in lines:\n",
    "                    if line.startswith(\"track\"):\n",
    "                        f.write(line)  # Заголовок сохраняем без изменений\n",
    "                    else:\n",
    "                        # Разбираем строку bedGraph\n",
    "                        chrom, pos_start, pos_end, val = line.strip().split(\"\\t\")\n",
    "                        pos_start = int(pos_start) + shift\n",
    "                        pos_end = int(pos_end) + shift\n",
    "                        # Записываем сдвинутые координаты\n",
    "                        f.write(f\"{chrom}\\t{pos_start}\\t{pos_end}\\t{val}\\n\")\n",
    "\n",
    "    print(f\"Сдвиг координат на {shift} баз завершен.\")\n",
    "\n",
    "# Запускаем сдвиг\n",
    "shift_bedgraph_files(\"predicted_expression_by_chromosomes/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1744b7cb-ae20-47c4-a3fa-1d91d5f5b2b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Файл переименован: borzoi_rnaseq_fold3_ENCFF133LYJ+_fw.bedGraph -> borzoi_rnaseq_fold3_ENCSR763OMY_fw.bedGraph\n",
      "Файл переименован: borzoi_rnaseq_fold3_ENCFF253SBE-_rc.bedGraph -> borzoi_rnaseq_fold3_ENCSR357BYU_rc.bedGraph\n",
      "Файл переименован: borzoi_rnaseq_fold3_ENCFF905NZB+_rc.bedGraph -> borzoi_rnaseq_fold3_ENCSR045GTF_rc.bedGraph\n",
      "Файл переименован: borzoi_rnaseq_fold3_ENCFF649RYB+_fw.bedGraph -> borzoi_rnaseq_fold3_ENCSR892LBU_fw.bedGraph\n",
      "Файл переименован: borzoi_rnaseq_fold3_ENCFF253SBE-_fw.bedGraph -> borzoi_rnaseq_fold3_ENCSR357BYU_fw.bedGraph\n",
      "Файл переименован: borzoi_rnaseq_fold3_ENCFF656OUX-_rc.bedGraph -> borzoi_rnaseq_fold3_ENCSR071DYD_rc.bedGraph\n",
      "Файл переименован: borzoi_rnaseq_fold3_ENCFF905NZB-_fw.bedGraph -> borzoi_rnaseq_fold3_ENCSR045GTF_fw.bedGraph\n",
      "Файл переименован: borzoi_rnaseq_fold3_ENCFF905NZB+_fw.bedGraph -> borzoi_rnaseq_fold3_ENCSR045GTF_fw.bedGraph\n",
      "Файл переименован: borzoi_rnaseq_fold3_ENCFF905NZB-_rc.bedGraph -> borzoi_rnaseq_fold3_ENCSR045GTF_rc.bedGraph\n",
      "Файл переименован: borzoi_rnaseq_fold3_ENCFF649RYB-_rc.bedGraph -> borzoi_rnaseq_fold3_ENCSR892LBU_rc.bedGraph\n",
      "Файл переименован: borzoi_rnaseq_fold3_ENCFF253SBE+_rc.bedGraph -> borzoi_rnaseq_fold3_ENCSR357BYU_rc.bedGraph\n",
      "Файл переименован: borzoi_rnaseq_fold3_ENCFF253SBE+_fw.bedGraph -> borzoi_rnaseq_fold3_ENCSR357BYU_fw.bedGraph\n",
      "Файл переименован: borzoi_rnaseq_fold3_ENCFF656OUX-_fw.bedGraph -> borzoi_rnaseq_fold3_ENCSR071DYD_fw.bedGraph\n",
      "Файл переименован: borzoi_rnaseq_fold3_ENCFF656OUX+_rc.bedGraph -> borzoi_rnaseq_fold3_ENCSR071DYD_rc.bedGraph\n",
      "Файл переименован: borzoi_rnaseq_fold3_ENCFF649RYB+_rc.bedGraph -> borzoi_rnaseq_fold3_ENCSR892LBU_rc.bedGraph\n",
      "Файл переименован: borzoi_rnaseq_fold3_ENCFF133LYJ+_rc.bedGraph -> borzoi_rnaseq_fold3_ENCSR763OMY_rc.bedGraph\n",
      "Файл переименован: borzoi_rnaseq_fold3_ENCFF649RYB-_fw.bedGraph -> borzoi_rnaseq_fold3_ENCSR892LBU_fw.bedGraph\n",
      "Файл переименован: borzoi_rnaseq_fold3_ENCFF133LYJ-_fw.bedGraph -> borzoi_rnaseq_fold3_ENCSR763OMY_fw.bedGraph\n",
      "Файл переименован: borzoi_rnaseq_fold3_ENCFF656OUX+_fw.bedGraph -> borzoi_rnaseq_fold3_ENCSR071DYD_fw.bedGraph\n",
      "Файл переименован: borzoi_rnaseq_fold3_ENCFF133LYJ-_rc.bedGraph -> borzoi_rnaseq_fold3_ENCSR763OMY_rc.bedGraph\n",
      "Переименование файлов завершено.\n"
     ]
    }
   ],
   "source": [
    "#НЕ ИСПОЛЬЗОВАТЬ!\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Папка с исходными файлами\n",
    "input_dir = \"predicted_expression_by_chromosomes/\"\n",
    "output_dir = \"predicted_expression_by_chromosomes_renamed/\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Проходим по всем файлам в папке\n",
    "for file_name in os.listdir(input_dir):\n",
    "    if file_name.endswith(\".bedGraph\"):\n",
    "        # Извлекаем название эксперимента из имени файла\n",
    "        # Например, \"borzoi_rnaseq_fold3_ENCFF133LYJ-_fw.bedGraph\" -> \"ENCFF133LYJ\"\n",
    "        experiment_name = file_name.split(\"_\")[3]\n",
    "        \n",
    "        # Находим строку в targets_df, где file_id содержит experiment_name\n",
    "        matching_row = targets_df[targets_df['file_id'].apply(lambda x: experiment_name in x)]\n",
    "        \n",
    "        if not matching_row.empty:\n",
    "            # Получаем правильный file_path из строки\n",
    "            file_path = matching_row['file_path'].values[0]\n",
    "            \n",
    "            # Строим новое имя файла, используя часть file_path\n",
    "            # Например, из file_path '/home/drk/tillage/datasets/human/rna/encode/ENCSR045GTF/summary/coverage+.w5'\n",
    "            # мы получим 'ENCSR045GTF' (часть пути)\n",
    "            experiment_folder = file_path.split(\"/\")[-3]\n",
    "            \n",
    "            # Строим новое имя файла, добавляя суффиксы fw или rc\n",
    "            suffix = \"_fw\" if \"_fw\" in file_name else \"_rc\"\n",
    "            new_file_name = f\"borzoi_rnaseq_{folds_str}_{experiment_folder}{suffix}.bedGraph\"\n",
    "            \n",
    "            # Полный путь к исходному и целевому файлу\n",
    "            original_file_path = os.path.join(input_dir, file_name)\n",
    "            new_file_path = os.path.join(output_dir, new_file_name)\n",
    "            \n",
    "            # Проверяем, существует ли файл и переименовываем\n",
    "            if os.path.exists(original_file_path):\n",
    "                shutil.move(original_file_path, new_file_path)\n",
    "                print(f\"Файл переименован: {file_name} -> {new_file_name}\")\n",
    "            else:\n",
    "                print(f\"Файл не найден: {file_name}\")\n",
    "        else:\n",
    "            print(f\"Эксперимент {experiment_name} не найден в file_id.\")\n",
    "\n",
    "print(\"Переименование файлов завершено.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
