{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1602a87d-54e4-400e-8dbc-10aaf5c51bb9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Импорты и проч"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "271f7532-07ed-462d-8f10-a863315ee1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импортируем необходимые библиотеки и функции\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pysam\n",
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "from baskerville import seqnn, gene as bgene\n",
    "from borzoi_helpers import process_sequence, predict_tracks  # предполагается, что эти функции доступны\n",
    "\n",
    "# Отключаем лишние предупреждения TensorFlow\n",
    "#tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0bcac038-f4bd-4d87-a73f-23d47108ff54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]\n",
      "2.14.0\n",
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2022 NVIDIA Corporation\n",
      "Built on Wed_Sep_21_10:33:58_PDT_2022\n",
      "Cuda compilation tools, release 11.8, V11.8.89\n",
      "Build cuda_11.8.r11.8/compiler.31833905_0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.config.list_physical_devices('GPU'))\n",
    "print(tf.__version__)\n",
    "!nvcc -V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "026b7f71-fe98-430a-a417-415cc9aecfb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f3c0 model already exists.\n",
      "f3c1 model already exists.\n",
      "f3c2 model already exists.\n",
      "f3c3 model already exists.\n",
      "Gene annotation already exists.\n",
      "Gene annotation (no read-through, protein-coding) already exists.\n",
      "lready exists.n (protein-coding) a\n",
      "TSS annotation already exists.\n",
      "Splice site annotation already exist.\n",
      "tation already exist.\n",
      "PolyA site annotation already exist.\n",
      "Human genome FASTA already exists.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "#Download model weights (data fold 3, 4 replicates)\n",
    "for rep in f3c0,f0 f3c1,f1 f3c2,f2 f3c3,f3; do IFS=\",\"; set -- $rep; \n",
    "  mkdir -p \"saved_models/$1/train\"\n",
    "  local_model=\"saved_models/$1/train/model0_best.h5\"\n",
    "  if [ -f \"$local_model\" ]; then\n",
    "    echo \"$1 model already exists.\"\n",
    "  else\n",
    "    wget --progress=bar:force \"https://storage.googleapis.com/seqnn-share/borzoi/$2/model0_best.h5\" -O \"$local_model\"\n",
    "  fi\n",
    "done\n",
    "\n",
    "#Download and uncompress annotation files\n",
    "mkdir -p hg38/genes/gencode41\n",
    "mkdir -p hg38/genes/polyadb\n",
    "\n",
    "if [ -f hg38/genes/gencode41/gencode41_basic_nort.gtf ]; then\n",
    "  echo \"Gene annotation already exists.\"\n",
    "else\n",
    "  wget -O - https://storage.googleapis.com/seqnn-share/helper/gencode41_basic_nort.gtf.gz | gunzip -c > hg38/genes/gencode41/gencode41_basic_nort.gtf\n",
    "fi\n",
    "\n",
    "if [ -f hg38/genes/gencode41/gencode41_basic_nort_protein.gtf ]; then\n",
    "  echo \"Gene annotation (no read-through, protein-coding) already exists.\"\n",
    "else\n",
    "  wget -O - https://storage.googleapis.com/seqnn-share/helper/gencode41_basic_nort_protein.gtf.gz | gunzip -c > hg38/genes/gencode41/gencode41_basic_nort_protein.gtf\n",
    "fi\n",
    "\n",
    "if [ -f hg38/genes/gencode41/gencode41_basic_protein.gtf ]; then\n",
    "  echo \"Gene annotation (protein-coding) already exists.\"\n",
    "else\n",
    "  wget -O - https://storage.googleapis.com/seqnn-share/helper/gencode41_basic_protein.gtf.gz | gunzip -c > hg38/genes/gencode41/gencode41_basic_protein.gtf\n",
    "fi\n",
    "\n",
    "if [ -f hg38/genes/gencode41/gencode41_basic_tss2.bed ]; then\n",
    "  echo \"TSS annotation already exists.\"\n",
    "else\n",
    "  wget -O - https://storage.googleapis.com/seqnn-share/helper/gencode41_basic_tss2.bed.gz | gunzip -c > hg38/genes/gencode41/gencode41_basic_tss2.bed\n",
    "fi\n",
    "\n",
    "if [ -f hg38/genes/gencode41/gencode41_basic_protein_splice.csv.gz ]; then\n",
    "  echo \"Splice site annotation already exist.\"\n",
    "else\n",
    "  wget https://storage.googleapis.com/seqnn-share/helper/gencode41_basic_protein_splice.csv.gz -O hg38/genes/gencode41/gencode41_basic_protein_splice.csv.gz\n",
    "fi\n",
    "\n",
    "if [ -f hg38/genes/gencode41/gencode41_basic_protein_splice.gff ]; then\n",
    "  echo \"Splice site annotation already exist.\"\n",
    "else\n",
    "  wget -O - https://storage.googleapis.com/seqnn-share/helper/gencode41_basic_protein_splice.gff.gz | gunzip -c > hg38/genes/gencode41/gencode41_basic_protein_splice.gff\n",
    "fi\n",
    "\n",
    "if [ -f hg38/genes/polyadb/polyadb_human_v3.csv.gz ]; then\n",
    "  echo \"PolyA site annotation already exist.\"\n",
    "else\n",
    "  wget https://storage.googleapis.com/seqnn-share/helper/polyadb_human_v3.csv.gz -O hg38/genes/polyadb/polyadb_human_v3.csv.gz\n",
    "fi\n",
    "\n",
    "#Download and index hg38 genome\n",
    "mkdir -p hg38/assembly/ucsc\n",
    "\n",
    "if [ -f hg38/assembly/ucsc/hg38.fa ]; then\n",
    "  echo \"Human genome FASTA already exists.\"\n",
    "else\n",
    "  wget -O - http://hgdownload.cse.ucsc.edu/goldenPath/hg38/bigZips/hg38.fa.gz | gunzip -c > hg38/assembly/ucsc/hg38.fa\n",
    "fi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "356f8eaf-d505-4ce8-9e9b-c5b544c50780",
   "metadata": {},
   "source": [
    "## Препроцессинг"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8710eb18-44df-4a87-b730-ef7972fd83e8",
   "metadata": {},
   "source": [
    "Код для понимания какой индекс отвечает за какую клеточную линию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a2dab8c-49cf-4558-876d-bc8151a7e099",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_id</th>\n",
       "      <th>file_path</th>\n",
       "      <th>clip</th>\n",
       "      <th>clip_soft</th>\n",
       "      <th>scale</th>\n",
       "      <th>sum_stat</th>\n",
       "      <th>strand_pair</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>identifier</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>identifier</td>\n",
       "      <td>file</td>\n",
       "      <td>clip</td>\n",
       "      <td>clip_soft</td>\n",
       "      <td>scale</td>\n",
       "      <td>sum_stat</td>\n",
       "      <td>strand_pair</td>\n",
       "      <td>description</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>CNhs10608+</td>\n",
       "      <td>/home/drk/tillage/datasets/human/cage/fantom/C...</td>\n",
       "      <td>768</td>\n",
       "      <td>384</td>\n",
       "      <td>1.0</td>\n",
       "      <td>sum</td>\n",
       "      <td>1</td>\n",
       "      <td>CAGE:Clontech Human Universal Reference Total ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>CNhs10608-</td>\n",
       "      <td>/home/drk/tillage/datasets/human/cage/fantom/C...</td>\n",
       "      <td>768</td>\n",
       "      <td>384</td>\n",
       "      <td>1.0</td>\n",
       "      <td>sum</td>\n",
       "      <td>0</td>\n",
       "      <td>CAGE:Clontech Human Universal Reference Total ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>CNhs10610+</td>\n",
       "      <td>/home/drk/tillage/datasets/human/cage/fantom/C...</td>\n",
       "      <td>768</td>\n",
       "      <td>384</td>\n",
       "      <td>1.0</td>\n",
       "      <td>sum</td>\n",
       "      <td>3</td>\n",
       "      <td>CAGE:SABiosciences XpressRef Human Universal T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>CNhs10610-</td>\n",
       "      <td>/home/drk/tillage/datasets/human/cage/fantom/C...</td>\n",
       "      <td>768</td>\n",
       "      <td>384</td>\n",
       "      <td>1.0</td>\n",
       "      <td>sum</td>\n",
       "      <td>2</td>\n",
       "      <td>CAGE:SABiosciences XpressRef Human Universal T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>CNhs10612+</td>\n",
       "      <td>/home/drk/tillage/datasets/human/cage/fantom/C...</td>\n",
       "      <td>768</td>\n",
       "      <td>384</td>\n",
       "      <td>1.0</td>\n",
       "      <td>sum</td>\n",
       "      <td>5</td>\n",
       "      <td>CAGE:Universal RNA - Human Normal Tissues Bioc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>CNhs10612-</td>\n",
       "      <td>/home/drk/tillage/datasets/human/cage/fantom/C...</td>\n",
       "      <td>768</td>\n",
       "      <td>384</td>\n",
       "      <td>1.0</td>\n",
       "      <td>sum</td>\n",
       "      <td>4</td>\n",
       "      <td>CAGE:Universal RNA - Human Normal Tissues Bioc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6.0</th>\n",
       "      <td>CNhs10615+</td>\n",
       "      <td>/home/drk/tillage/datasets/human/cage/fantom/C...</td>\n",
       "      <td>768</td>\n",
       "      <td>384</td>\n",
       "      <td>1.0</td>\n",
       "      <td>sum</td>\n",
       "      <td>7</td>\n",
       "      <td>CAGE:adipose tissue, adult, pool1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7.0</th>\n",
       "      <td>CNhs10615-</td>\n",
       "      <td>/home/drk/tillage/datasets/human/cage/fantom/C...</td>\n",
       "      <td>768</td>\n",
       "      <td>384</td>\n",
       "      <td>1.0</td>\n",
       "      <td>sum</td>\n",
       "      <td>6</td>\n",
       "      <td>CAGE:adipose tissue, adult, pool1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8.0</th>\n",
       "      <td>CNhs10616+</td>\n",
       "      <td>/home/drk/tillage/datasets/human/cage/fantom/C...</td>\n",
       "      <td>768</td>\n",
       "      <td>384</td>\n",
       "      <td>1.0</td>\n",
       "      <td>sum</td>\n",
       "      <td>9</td>\n",
       "      <td>CAGE:bladder, adult, pool1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               file_id                                          file_path  \\\n",
       "identifier                                                                  \n",
       "NaN         identifier                                               file   \n",
       "0.0         CNhs10608+  /home/drk/tillage/datasets/human/cage/fantom/C...   \n",
       "1.0         CNhs10608-  /home/drk/tillage/datasets/human/cage/fantom/C...   \n",
       "2.0         CNhs10610+  /home/drk/tillage/datasets/human/cage/fantom/C...   \n",
       "3.0         CNhs10610-  /home/drk/tillage/datasets/human/cage/fantom/C...   \n",
       "4.0         CNhs10612+  /home/drk/tillage/datasets/human/cage/fantom/C...   \n",
       "5.0         CNhs10612-  /home/drk/tillage/datasets/human/cage/fantom/C...   \n",
       "6.0         CNhs10615+  /home/drk/tillage/datasets/human/cage/fantom/C...   \n",
       "7.0         CNhs10615-  /home/drk/tillage/datasets/human/cage/fantom/C...   \n",
       "8.0         CNhs10616+  /home/drk/tillage/datasets/human/cage/fantom/C...   \n",
       "\n",
       "            clip  clip_soft  scale  sum_stat  strand_pair  \\\n",
       "identifier                                                  \n",
       "NaN         clip  clip_soft  scale  sum_stat  strand_pair   \n",
       "0.0          768        384    1.0       sum            1   \n",
       "1.0          768        384    1.0       sum            0   \n",
       "2.0          768        384    1.0       sum            3   \n",
       "3.0          768        384    1.0       sum            2   \n",
       "4.0          768        384    1.0       sum            5   \n",
       "5.0          768        384    1.0       sum            4   \n",
       "6.0          768        384    1.0       sum            7   \n",
       "7.0          768        384    1.0       sum            6   \n",
       "8.0          768        384    1.0       sum            9   \n",
       "\n",
       "                                                  description  \n",
       "identifier                                                     \n",
       "NaN                                               description  \n",
       "0.0         CAGE:Clontech Human Universal Reference Total ...  \n",
       "1.0         CAGE:Clontech Human Universal Reference Total ...  \n",
       "2.0         CAGE:SABiosciences XpressRef Human Universal T...  \n",
       "3.0         CAGE:SABiosciences XpressRef Human Universal T...  \n",
       "4.0         CAGE:Universal RNA - Human Normal Tissues Bioc...  \n",
       "5.0         CAGE:Universal RNA - Human Normal Tissues Bioc...  \n",
       "6.0                         CAGE:adipose tissue, adult, pool1  \n",
       "7.0                         CAGE:adipose tissue, adult, pool1  \n",
       "8.0                                CAGE:bladder, adult, pool1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эксперименты, которые подходят (в file_path содержат нужные ID):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_path</th>\n",
       "      <th>clip</th>\n",
       "      <th>clip_soft</th>\n",
       "      <th>scale</th>\n",
       "      <th>sum_stat</th>\n",
       "      <th>strand_pair</th>\n",
       "      <th>description</th>\n",
       "      <th>local_index</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>identifier</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6396.0</th>\n",
       "      <td>/home/drk/tillage/datasets/human/rna/encode/EN...</td>\n",
       "      <td>768</td>\n",
       "      <td>384</td>\n",
       "      <td>0.3</td>\n",
       "      <td>sum_sqrt</td>\n",
       "      <td>6397</td>\n",
       "      <td>RNA:lung tissue female adult (47 years)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6397.0</th>\n",
       "      <td>/home/drk/tillage/datasets/human/rna/encode/EN...</td>\n",
       "      <td>768</td>\n",
       "      <td>384</td>\n",
       "      <td>0.3</td>\n",
       "      <td>sum_sqrt</td>\n",
       "      <td>6396</td>\n",
       "      <td>RNA:lung tissue female adult (47 years)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6423.0</th>\n",
       "      <td>/home/drk/tillage/datasets/human/rna/encode/EN...</td>\n",
       "      <td>768</td>\n",
       "      <td>384</td>\n",
       "      <td>0.3</td>\n",
       "      <td>sum_sqrt</td>\n",
       "      <td>6424</td>\n",
       "      <td>RNA:pancreas tissue female child (16 years)</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6424.0</th>\n",
       "      <td>/home/drk/tillage/datasets/human/rna/encode/EN...</td>\n",
       "      <td>768</td>\n",
       "      <td>384</td>\n",
       "      <td>0.3</td>\n",
       "      <td>sum_sqrt</td>\n",
       "      <td>6423</td>\n",
       "      <td>RNA:pancreas tissue female child (16 years)</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6730.0</th>\n",
       "      <td>/home/drk/tillage/datasets/human/rna/encode/EN...</td>\n",
       "      <td>768</td>\n",
       "      <td>384</td>\n",
       "      <td>0.3</td>\n",
       "      <td>sum_sqrt</td>\n",
       "      <td>6731</td>\n",
       "      <td>RNA:left lobe of liver tissue male adult (45 y...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6731.0</th>\n",
       "      <td>/home/drk/tillage/datasets/human/rna/encode/EN...</td>\n",
       "      <td>768</td>\n",
       "      <td>384</td>\n",
       "      <td>0.3</td>\n",
       "      <td>sum_sqrt</td>\n",
       "      <td>6730</td>\n",
       "      <td>RNA:left lobe of liver tissue male adult (45 y...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7240.0</th>\n",
       "      <td>/home/drk/tillage/datasets/human/rna/encode/EN...</td>\n",
       "      <td>768</td>\n",
       "      <td>384</td>\n",
       "      <td>0.3</td>\n",
       "      <td>sum_sqrt</td>\n",
       "      <td>7241</td>\n",
       "      <td>RNA:adrenal gland tissue female adult (41 years)</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7241.0</th>\n",
       "      <td>/home/drk/tillage/datasets/human/rna/encode/EN...</td>\n",
       "      <td>768</td>\n",
       "      <td>384</td>\n",
       "      <td>0.3</td>\n",
       "      <td>sum_sqrt</td>\n",
       "      <td>7240</td>\n",
       "      <td>RNA:adrenal gland tissue female adult (41 years)</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7396.0</th>\n",
       "      <td>/home/drk/tillage/datasets/human/rna/encode/EN...</td>\n",
       "      <td>768</td>\n",
       "      <td>384</td>\n",
       "      <td>0.3</td>\n",
       "      <td>sum_sqrt</td>\n",
       "      <td>7397</td>\n",
       "      <td>RNA:kidney tissue female adult (47 years)</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7397.0</th>\n",
       "      <td>/home/drk/tillage/datasets/human/rna/encode/EN...</td>\n",
       "      <td>768</td>\n",
       "      <td>384</td>\n",
       "      <td>0.3</td>\n",
       "      <td>sum_sqrt</td>\n",
       "      <td>7396</td>\n",
       "      <td>RNA:kidney tissue female adult (47 years)</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    file_path clip clip_soft  \\\n",
       "identifier                                                                     \n",
       "6396.0      /home/drk/tillage/datasets/human/rna/encode/EN...  768       384   \n",
       "6397.0      /home/drk/tillage/datasets/human/rna/encode/EN...  768       384   \n",
       "6423.0      /home/drk/tillage/datasets/human/rna/encode/EN...  768       384   \n",
       "6424.0      /home/drk/tillage/datasets/human/rna/encode/EN...  768       384   \n",
       "6730.0      /home/drk/tillage/datasets/human/rna/encode/EN...  768       384   \n",
       "6731.0      /home/drk/tillage/datasets/human/rna/encode/EN...  768       384   \n",
       "7240.0      /home/drk/tillage/datasets/human/rna/encode/EN...  768       384   \n",
       "7241.0      /home/drk/tillage/datasets/human/rna/encode/EN...  768       384   \n",
       "7396.0      /home/drk/tillage/datasets/human/rna/encode/EN...  768       384   \n",
       "7397.0      /home/drk/tillage/datasets/human/rna/encode/EN...  768       384   \n",
       "\n",
       "           scale  sum_stat strand_pair  \\\n",
       "identifier                               \n",
       "6396.0       0.3  sum_sqrt        6397   \n",
       "6397.0       0.3  sum_sqrt        6396   \n",
       "6423.0       0.3  sum_sqrt        6424   \n",
       "6424.0       0.3  sum_sqrt        6423   \n",
       "6730.0       0.3  sum_sqrt        6731   \n",
       "6731.0       0.3  sum_sqrt        6730   \n",
       "7240.0       0.3  sum_sqrt        7241   \n",
       "7241.0       0.3  sum_sqrt        7240   \n",
       "7396.0       0.3  sum_sqrt        7397   \n",
       "7397.0       0.3  sum_sqrt        7396   \n",
       "\n",
       "                                                  description  local_index  \n",
       "identifier                                                                  \n",
       "6396.0                RNA:lung tissue female adult (47 years)            0  \n",
       "6397.0                RNA:lung tissue female adult (47 years)            1  \n",
       "6423.0            RNA:pancreas tissue female child (16 years)            2  \n",
       "6424.0            RNA:pancreas tissue female child (16 years)            3  \n",
       "6730.0      RNA:left lobe of liver tissue male adult (45 y...            4  \n",
       "6731.0      RNA:left lobe of liver tissue male adult (45 y...            5  \n",
       "7240.0       RNA:adrenal gland tissue female adult (41 years)            6  \n",
       "7241.0       RNA:adrenal gland tissue female adult (41 years)            7  \n",
       "7396.0              RNA:kidney tissue female adult (47 years)            8  \n",
       "7397.0              RNA:kidney tissue female adult (47 years)            9  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Список глобальных индексов (int32) таргетов: [6396 6397 6423 6424 6730 6731 7240 7241 7396 7397]\n"
     ]
    }
   ],
   "source": [
    "# ---  Препроцессинг ---\n",
    "\n",
    "targets_file = 'targets_human.txt'\n",
    "col_names = [\n",
    "    \"identifier\",\n",
    "    \"file_id\",\n",
    "    \"file_path\",\n",
    "    \"clip\",\n",
    "    \"clip_soft\",\n",
    "    \"scale\",\n",
    "    \"sum_stat\",\n",
    "    \"strand_pair\",\n",
    "    \"description\",\n",
    "]\n",
    "\n",
    "targets_df = pd.read_csv(targets_file, sep='\\t', index_col=0, names=col_names)\n",
    "display(targets_df.head(10))\n",
    "\n",
    "# Эксперименты (судя по условию, ищем их в столбце \"file_path\")\n",
    "experiment_ids = [\n",
    "    \"ENCSR892LBU\",\n",
    "    \"ENCSR357BYU\",\n",
    "    \"ENCSR763OMY\",\n",
    "    \"ENCSR071DYD\",\n",
    "    \"ENCSR045GTF\",\n",
    "]\n",
    "\n",
    "def matches_exps(fp):\n",
    "    return any(eid in fp for eid in experiment_ids)\n",
    "\n",
    "filtered_df = targets_df[ targets_df['file_path'].apply(matches_exps) ].copy()\n",
    "filtered_df['local_index'] = range(len(filtered_df))\n",
    "print(\"Эксперименты, которые подходят (в file_path содержат нужные ID):\")\n",
    "display(filtered_df[['file_path','clip','clip_soft','scale','sum_stat','strand_pair','description','local_index']])\n",
    "\n",
    "# Собираем список глобальных индексов, потом приводим к int32, чтобы не было float\n",
    "target_index = filtered_df.index.to_numpy(dtype='int32')  # <-- ВАЖНО: dtype='int32'\n",
    "print(\"\\nСписок глобальных индексов (int32) таргетов:\", target_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8695c874-5af3-44f9-8413-5a91f8be2a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6888 строк до мерджа.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Мержим интервалы: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 17/17 [00:00<00:00, 1037.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "После мерджа: 46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chrom</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chr1</td>\n",
       "      <td>143479625</td>\n",
       "      <td>143823752</td>\n",
       "      <td>fold3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chr1</td>\n",
       "      <td>227321006</td>\n",
       "      <td>228550247</td>\n",
       "      <td>fold3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chr11</td>\n",
       "      <td>25440674</td>\n",
       "      <td>48748592</td>\n",
       "      <td>fold3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chr11</td>\n",
       "      <td>48896195</td>\n",
       "      <td>49191149</td>\n",
       "      <td>fold3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chr11</td>\n",
       "      <td>54525074</td>\n",
       "      <td>54820028</td>\n",
       "      <td>fold3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   chrom      start        end   fold\n",
       "0   chr1  143479625  143823752  fold3\n",
       "1   chr1  227321006  228550247  fold3\n",
       "2  chr11   25440674   48748592  fold3\n",
       "3  chr11   48896195   49191149  fold3\n",
       "4  chr11   54525074   54820028  fold3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Получения списка интервалов и их мерж ---\n",
    "\n",
    "import pandas as pd\n",
    "import gzip\n",
    "from tqdm import tqdm\n",
    "\n",
    "bed_file_path = '../data/sequences_human.bed.gz'\n",
    "bed_data = pd.read_csv(\n",
    "    bed_file_path,\n",
    "    sep='\\t',\n",
    "    header=None,\n",
    "    names=[\"chrom\", \"start\", \"end\", \"fold\"],\n",
    "    compression='gzip'\n",
    ")\n",
    "\n",
    "folds_to_process = ['fold3']  # Можно изменить\n",
    "filtered_bed_data = bed_data[ bed_data['fold'].isin(folds_to_process) ]\n",
    "grouped = filtered_bed_data.groupby(\"chrom\")\n",
    "\n",
    "print(len(filtered_bed_data),\"строк до мерджа.\")\n",
    "\n",
    "def merge_intervals(intervals):\n",
    "    intervals.sort(key=lambda x: x[0])\n",
    "    merged = []\n",
    "    for st, en in intervals:\n",
    "        if not merged or st > merged[-1][1]:\n",
    "            merged.append([st, en])\n",
    "        else:\n",
    "            merged[-1][1] = max(merged[-1][1], en)\n",
    "    return merged\n",
    "\n",
    "merged_intervals_list = []\n",
    "unique_chroms = filtered_bed_data['chrom'].nunique()\n",
    "for chrom, group in tqdm(filtered_bed_data.groupby(\"chrom\"), desc=\"Мержим интервалы\", total=unique_chroms):\n",
    "    intervals = group[['start','end']].values.tolist()\n",
    "    merged = merge_intervals(intervals)\n",
    "    fold_val = group['fold'].iloc[0]\n",
    "    for st, en in merged:\n",
    "        merged_intervals_list.append({'chrom': chrom, 'start': st, 'end': en, 'fold': fold_val})\n",
    "\n",
    "filtered_bed_data = pd.DataFrame(merged_intervals_list)\n",
    "print(\"После мерджа:\", len(filtered_bed_data))\n",
    "display(filtered_bed_data.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d775e26-5708-40d5-af32-fa13b6c8ba89",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Проверка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6d5dbf-18d6-4aff-a9c8-de8b5757820f",
   "metadata": {},
   "source": [
    "Убедимся что все записи влезут во входящее окно модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1871339-b2e9-400f-b396-42220742d447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Максимальная длина последовательности: 67957002 нуклеотидов\n"
     ]
    }
   ],
   "source": [
    "# Находим максимальную длину последовательности\n",
    "max_sequence_length = 0\n",
    "\n",
    "for index, row in filtered_bed_data.iterrows():\n",
    "    start = row['start']\n",
    "    end = row['end']\n",
    "    \n",
    "    # Вычисляем длину текущей последовательности\n",
    "    sequence_length = end - start\n",
    "    \n",
    "    # Обновляем максимальную длину, если текущая больше\n",
    "    if sequence_length > max_sequence_length:\n",
    "        max_sequence_length = sequence_length\n",
    "\n",
    "print(f\"Максимальная длина последовательности: {max_sequence_length} нуклеотидов\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f98bc5-6983-463d-aad5-37a9d8d37ab3",
   "metadata": {},
   "source": [
    "Проверка на пересечения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50821f49-ce28-4efa-8a56-522b05a40531",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking for overlaps: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 17/17 [00:00<00:00, 1105.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Пересечений не обнаружено в filtered_bed_data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "overlap_found = False\n",
    "\n",
    "# Получаем список уникальных хромосом\n",
    "chromosomes = filtered_bed_data['chrom'].unique()\n",
    "\n",
    "# Используем tqdm для отображения прогресса\n",
    "for chrom in tqdm(chromosomes, desc=\"Checking for overlaps\"):\n",
    "    # Фильтруем по текущей хромосоме\n",
    "    group = filtered_bed_data[filtered_bed_data['chrom'] == chrom]\n",
    "    \n",
    "    # Сортируем записи по старту\n",
    "    sorted_group = group.sort_values('start')\n",
    "    \n",
    "    # Инициализируем предыдущую запись\n",
    "    prev_row = None\n",
    "    \n",
    "    # Проходим по отсортированным записям\n",
    "    for idx, row in sorted_group.iterrows():\n",
    "        if prev_row is not None:\n",
    "            # Проверяем пересечение\n",
    "            if row['start'] < prev_row['end']:\n",
    "                print(f\"Пересечение на {chrom}: {prev_row[['start', 'end']].to_dict()} и {row[['start', 'end']].to_dict()}\")\n",
    "                overlap_found = True\n",
    "        prev_row = row\n",
    "\n",
    "if not overlap_found:\n",
    "    print(\"Пересечений не обнаружено в filtered_bed_data.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "484758a2-709d-4f14-b2f9-86219a181aa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Уникальные хромосомы в выборке:\n",
      "['chr5' 'chr11' 'chr6' 'chr9' 'chr13' 'chr2' 'chr8' 'chr7' 'chr17' 'chrX'\n",
      " 'chr18' 'chr12' 'chr15' 'chr19' 'chr1' 'chr16' 'chr20']\n",
      "Количество уникальных хромосом: 17\n",
      "\n",
      "Минимальный start и максимальный end по хромосомам:\n",
      "       min_start    max_end\n",
      "chrom                      \n",
      "chr1   143479625  228550247\n",
      "chr11   25440674   56541083\n",
      "chr12   32992234   34368994\n",
      "chr13   40653298  102135774\n",
      "chr15   20168638   34675550\n",
      "chr16   33491584   33884884\n",
      "chr17   81799133   83225066\n",
      "chr18   13485786   15206757\n",
      "chr19    3108622    9156817\n",
      "chr2    68747521  129505661\n",
      "chr20   30186694   30383302\n",
      "chr5     8770274  103148800\n",
      "chr6    99603327  170690035\n",
      "chr7       10000   74778699\n",
      "chr8     8158857   55824055\n",
      "chr9    80588528  138217638\n",
      "chrX     3230043   58109050\n",
      "\n",
      "Выборка содержит более одной хромосомы.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import gzip\n",
    "\n",
    "# Загрузим данные из bed-файла\n",
    "bed_file_path = '../data/sequences_human.bed.gz'\n",
    "with gzip.open(bed_file_path, 'rt') as file:\n",
    "    bed_data = pd.read_csv(file, sep='\\t', header=None, \n",
    "                           names=[\"chrom\", \"start\", \"end\", \"fold\"])\n",
    "\n",
    "# Фильтруем данные по fold3 и fold4\n",
    "#folds_to_process = ['fold3', 'fold4']\n",
    "folds_to_process = ['fold3']\n",
    "filtered_bed_data = bed_data[bed_data['fold'].isin(folds_to_process)]\n",
    "\n",
    "# Выведем список уникальных хромосом\n",
    "unique_chroms = filtered_bed_data['chrom'].unique()\n",
    "print(\"Уникальные хромосомы в выборке:\")\n",
    "print(unique_chroms)\n",
    "print(f\"Количество уникальных хромосом: {len(unique_chroms)}\")\n",
    "\n",
    "# Для каждой хромосомы находим минимальный start и максимальный end\n",
    "chrom_stats = filtered_bed_data.groupby(\"chrom\").agg(min_start=('start', 'min'),\n",
    "                                                      max_end=('end', 'max'))\n",
    "print(\"\\nМинимальный start и максимальный end по хромосомам:\")\n",
    "print(chrom_stats)\n",
    "\n",
    "if len(unique_chroms) > 1:\n",
    "    print(\"\\nВыборка содержит более одной хромосомы.\")\n",
    "else:\n",
    "    print(\"\\nВыборка содержит только одну хромосому.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f758c39f-4ea0-4315-ba25-88035f51f983",
   "metadata": {},
   "source": [
    "## Модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8861ef2c-9185-4c8e-9011-b591d8e08535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Загружено 4 моделей, каждая со срезом по 10 каналам.\n",
      "Параметры первой модели:\n",
      " stride = 32 crop = 16 tlen = 16352\n"
     ]
    }
   ],
   "source": [
    "# --- ЯЧЕЙКА 5: Инициализация моделей (n_reps) ---\n",
    "\n",
    "params_file = 'params_pred.json'\n",
    "with open(params_file) as f:\n",
    "    params = json.load(f)\n",
    "params_model = params['model']\n",
    "params_train = params['train']\n",
    "\n",
    "# ВАЖНО: n_reps > 1 => несколько реплик\n",
    "n_reps = 4  # или 1, если хотим 1\n",
    "rc = False  # мы не усредняем rc, т.к. +/– цепи разные каналы\n",
    "# Папки: f3c0, f3c1, f3c2, f3c3\n",
    "\n",
    "models = []\n",
    "for rep_ix in range(n_reps):\n",
    "    model_file = f\"saved_models/f3c{rep_ix}/train/model0_best.h5\"\n",
    "\n",
    "    seqnn_model = seqnn.SeqNN(params_model)\n",
    "    seqnn_model.restore(model_file, 0)\n",
    "\n",
    "    # Используем build_slice(...) по target_index (из ЯЧЕЙКИ 2)\n",
    "    seqnn_model.build_slice(target_index)\n",
    "\n",
    "    # build_ensemble\n",
    "    seqnn_model.build_ensemble(rc, [0])\n",
    "    \n",
    "    models.append(seqnn_model)\n",
    "\n",
    "print(f\"Загружено {n_reps} моделей, каждая со срезом по {len(target_index)} каналам.\")\n",
    "print(\"Параметры первой модели:\")\n",
    "print(\" stride =\", models[0].model_strides[0],\n",
    "      \"crop =\", models[0].target_crops[0],\n",
    "      \"tlen =\", models[0].target_lengths[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6f1fac8c-f4b6-4435-8ca2-30f65022126a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Model Summary ===\n",
      "Model: \"model_27\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " sequence (InputLayer)       [(None, 524288, 4)]       0         \n",
      "                                                                 \n",
      " model_25 (Functional)       (None, 16352, 7611)       185917723 \n",
      "                                                                 \n",
      " tf.compat.v1.gather_7 (TFO  (None, 16352, 10)         0         \n",
      " pLambda)                                                        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 185917723 (709.22 MB)\n",
      "Trainable params: 185892699 (709.12 MB)\n",
      "Non-trainable params: 25024 (97.75 KB)\n",
      "_________________________________________________________________\n",
      "\n",
      "=== Model Parameters ===\n",
      "stride         = 32\n",
      "crop           = 16\n",
      "target_length  = 16352\n",
      "\n",
      "Dummy sequence shape: (524288, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-20 17:47:08.375412: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8902\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Raw Prediction Output (прямая цепь) ===\n",
      "dummy_pred.shape = (1, 1, 16352, 10)\n",
      "После индексирования y_plus.shape = (1, 10)\n",
      "\n",
      "=== Raw Prediction Output (реверс-компл.) ===\n",
      "dummy_pred_rc.shape = (1, 1, 16352, 10)\n",
      "После индексирования y_minus.shape = (1, 10)\n",
      "\n",
      "=== Примеры статистики выходного тензора ===\n",
      "Прямая цепь: min = 0.003132 max = 0.06027\n",
      "Реверс цепь: min = 0.01021 max = 0.03714\n"
     ]
    }
   ],
   "source": [
    "def debug_model(model, seq_len=524288):\n",
    "    \"\"\"\n",
    "    Отладочная функция для проверки работы модели.\n",
    "    Выводит:\n",
    "      - модельную сводку (summary)\n",
    "      - ключевые параметры: stride, crop, target_length\n",
    "      - форму входного (dummy) массива\n",
    "      - форму выходных предсказаний (для прямой и реверс-комплементарной последовательностей)\n",
    "    \"\"\"\n",
    "    print(\"=== Model Summary ===\")\n",
    "    model.model.summary()\n",
    "    \n",
    "    print(\"\\n=== Model Parameters ===\")\n",
    "    print(f\"stride         = {model.model_strides[0]}\")\n",
    "    print(f\"crop           = {model.target_crops[0]}\")\n",
    "    print(f\"target_length  = {model.target_lengths[0]}\")\n",
    "    \n",
    "    # Создадим dummy one-hot последовательность\n",
    "    # Каждая строка будет ровно одной единицей на 4 элементах.\n",
    "    dummy_seq = np.zeros((seq_len, 4), dtype=np.float32)\n",
    "    for i in range(seq_len):\n",
    "        dummy_seq[i, np.random.randint(0, 4)] = 1.0\n",
    "    print(\"\\nDummy sequence shape:\", dummy_seq.shape)\n",
    "    \n",
    "    # Предсказание для прямой цепи\n",
    "    dummy_pred = predict_tracks([model], dummy_seq)\n",
    "    print(\"\\n=== Raw Prediction Output (прямая цепь) ===\")\n",
    "    print(\"dummy_pred.shape =\", dummy_pred.shape)\n",
    "    # Ожидается форма вроде: [1, L_out, X, C]. Попробуем взять replicate=0 и strand=0:\n",
    "    try:\n",
    "        y_plus = dummy_pred[0, :, 0, :]\n",
    "        print(\"После индексирования y_plus.shape =\", y_plus.shape)\n",
    "    except Exception as e:\n",
    "        print(\"Ошибка индексирования y_plus:\", e)\n",
    "    \n",
    "    # Предсказание для реверс-комплементарного входа\n",
    "    def reverse_complement_onehot(seq_onehot):\n",
    "        rev = np.flip(seq_onehot, axis=0)\n",
    "        revcomp = rev[:, [3,2,1,0]]\n",
    "        return revcomp\n",
    "\n",
    "    dummy_seq_rc = reverse_complement_onehot(dummy_seq)\n",
    "    dummy_pred_rc = predict_tracks([model], dummy_seq_rc)\n",
    "    print(\"\\n=== Raw Prediction Output (реверс-компл.) ===\")\n",
    "    print(\"dummy_pred_rc.shape =\", dummy_pred_rc.shape)\n",
    "    try:\n",
    "        y_minus = dummy_pred_rc[0, :, 0, :]\n",
    "        print(\"После индексирования y_minus.shape =\", y_minus.shape)\n",
    "    except Exception as e:\n",
    "        print(\"Ошибка индексирования y_minus:\", e)\n",
    "    \n",
    "    # Можно вывести также максимальные и минимальные значения предсказания\n",
    "    print(\"\\n=== Примеры статистики выходного тензора ===\")\n",
    "    print(\"Прямая цепь: min =\", np.min(y_plus), \"max =\", np.max(y_plus))\n",
    "    print(\"Реверс цепь: min =\", np.min(y_minus), \"max =\", np.max(y_minus))\n",
    "\n",
    "\n",
    "# Запускаем отладку модели:\n",
    "debug_model(seqnn_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6bb2fe65-88bc-448d-9a3c-1479dc26a168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Пример chr_sizes: [('chr1', 248956422), ('chr10', 133797422), ('chr11', 135086622)]\n"
     ]
    }
   ],
   "source": [
    "# --- ЯЧЕЙКА 6: Загрузка FASTA, chr_sizes ---\n",
    "\n",
    "fasta_path = \"hg38/assembly/ucsc/hg38.fa\"\n",
    "fasta_index = pysam.Fastafile(fasta_path)\n",
    "chr_sizes = {c: fasta_index.get_reference_length(c) for c in fasta_index.references}\n",
    "print(\"Пример chr_sizes:\", list(chr_sizes.items())[:3])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70cfab9c-871c-4cfc-89cb-540d2ae9721e",
   "metadata": {},
   "source": [
    "# Инференс"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7de044f1-8a87-4cbe-ba57-371c53189a13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Всего сформировано 1785 окон.\n"
     ]
    }
   ],
   "source": [
    "# --- Формирование окон ---\n",
    "\n",
    "center_len = 196_608\n",
    "context_len = 163_840\n",
    "\n",
    "all_windows = []\n",
    "for _, row in filtered_bed_data.iterrows():\n",
    "    chrom = row['chrom']\n",
    "    st_merged = row['start']\n",
    "    en_merged = row['end']\n",
    "    curr_start = st_merged\n",
    "    while curr_start < en_merged:\n",
    "        curr_end = curr_start + center_len\n",
    "        if curr_end > en_merged:\n",
    "            curr_end = en_merged\n",
    "        all_windows.append((chrom, curr_start, curr_end))\n",
    "        curr_start = curr_end\n",
    "\n",
    "print(\"Всего сформировано\", len(all_windows), \"окон.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "af85e3e4-7aec-40d8-afc2-850818848728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folds_str= fold3\n",
      "Предсозданы файлы bedGraph для каждого канала:\n",
      "predicted_expression_by_chromosomes/borzoi_rnaseq_fold3_ENCFF905NZB+.bedGraph\n",
      "predicted_expression_by_chromosomes/borzoi_rnaseq_fold3_ENCFF905NZB-.bedGraph\n",
      "predicted_expression_by_chromosomes/borzoi_rnaseq_fold3_ENCFF656OUX+.bedGraph\n",
      "predicted_expression_by_chromosomes/borzoi_rnaseq_fold3_ENCFF656OUX-.bedGraph\n",
      "predicted_expression_by_chromosomes/borzoi_rnaseq_fold3_ENCFF253SBE+.bedGraph\n",
      "predicted_expression_by_chromosomes/borzoi_rnaseq_fold3_ENCFF253SBE-.bedGraph\n",
      "predicted_expression_by_chromosomes/borzoi_rnaseq_fold3_ENCFF133LYJ+.bedGraph\n",
      "predicted_expression_by_chromosomes/borzoi_rnaseq_fold3_ENCFF133LYJ-.bedGraph\n",
      "predicted_expression_by_chromosomes/borzoi_rnaseq_fold3_ENCFF649RYB+.bedGraph\n",
      "predicted_expression_by_chromosomes/borzoi_rnaseq_fold3_ENCFF649RYB-.bedGraph\n"
     ]
    }
   ],
   "source": [
    "# --- Предсоздание bedGraph файлов ---\n",
    "\n",
    "output_dir = \"predicted_expression_by_chromosomes/\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "folds_str = \"_\".join(['fold3'])  # или что-то другое\n",
    "print(\"folds_str=\", folds_str)\n",
    "\n",
    "# Так как у нас теперь нет явных \"chains = st+ st-\", \n",
    "# но у каждого канала (experiments) может быть coverage+ или coverage-. \n",
    "# мы будем называть файл \"borzoi_rnaseq_{folds_str}_{target_id}.bedGraph\"\n",
    "# (вместо st+ / st-).\n",
    "for tid in target_index:\n",
    "    # Для удобства, сформируем имя файла из 'file_id' (или 'identifier')\n",
    "    # Но в \"targets_human.txt\" 1-й столбец — identifier, 2-й — file_id, 3-й — file_path, ...\n",
    "    # filtered_df.loc[tid] содержит нужную инфу\n",
    "    row = targets_df.loc[tid]\n",
    "    file_id = row['file_id']\n",
    "    bed_path = os.path.join(output_dir, f\"borzoi_rnaseq_{folds_str}_{file_id}.bedGraph\")\n",
    "    with open(bed_path, \"w\") as f:\n",
    "        f.write(f\"track type=bedGraph name=\\\"{file_id}\\\"\\n\")\n",
    "\n",
    "print(\"Предсозданы файлы bedGraph для каждого канала:\")\n",
    "for tid in target_index:\n",
    "    file_id = targets_df.loc[tid,'file_id']\n",
    "    bed_path = os.path.join(output_dir, f\"borzoi_rnaseq_{folds_str}_{file_id}.bedGraph\")\n",
    "    print(bed_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ded98b6a-080f-4981-9bc8-1e4740a552fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- обратная трансформация ---\n",
    "\n",
    "def inverse_transform(y_array, clip, clip_soft, scale, sum_stat):\n",
    "    \"\"\"\n",
    "    Упрощённая логика «обратной» трансформации:\n",
    "    1) Делим на scale (если scale != 1)\n",
    "    2) Если sum_stat='sum_sqrt', снимаем clip_soft и sqrt\n",
    "       (как в примере: y->(y-clip_soft+1)**2 + clip_soft -1, потом (y+1)**2 -1)\n",
    "       иначе ничего не делаем.\n",
    "    \"\"\"\n",
    "    # Преобразуем входные параметры к float,\n",
    "    # чтобы избежать TypeError при делении (например, если они считались строками).\n",
    "    clip = float(clip) if clip is not None else 0.0\n",
    "    clip_soft = float(clip_soft) if clip_soft is not None else 0.0\n",
    "    scale = float(scale) if scale is not None else 1.0\n",
    "\n",
    "    # Переводим sum_stat в нижний регистр на всякий случай\n",
    "    if isinstance(sum_stat, str):\n",
    "        sum_stat = sum_stat.lower()\n",
    "    else:\n",
    "        sum_stat = \"\"\n",
    "\n",
    "    # Копируем массив в float32\n",
    "    y = np.array(y_array, dtype=np.float32)\n",
    "\n",
    "    # 1) Делим на scale\n",
    "    if scale != 1.0:\n",
    "        y /= scale\n",
    "\n",
    "    # 2) Если sum_stat='sum_sqrt', снимаем clip_soft + sqrt\n",
    "    if sum_stat == 'sum_sqrt':\n",
    "        if clip_soft > 0:\n",
    "            # (y - clip_soft +1)**2 + clip_soft -1\n",
    "            y_unclip = (y - clip_soft + 1.0)**2 + clip_soft - 1.0\n",
    "            mask = (y > clip_soft)\n",
    "            y[mask] = y_unclip[mask]\n",
    "        # Далее снимаем sqrt+1 => (y+1)**2 -1 (упрощённая логика)\n",
    "        y = (y + 1.0)**2 - 1.0\n",
    "\n",
    "    return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "455f01db-fdab-4b75-9366-94c1b0295815",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- ЯЧЕЙКА 10: Запуск инференса с обратной трансформацией ---\n",
    "\n",
    "def run_inference(all_windows, models):\n",
    "    start_time = time.time()\n",
    "    print(f\"Начинаем инференс по {len(all_windows)} окнам.\")\n",
    "\n",
    "    stride = models[0].model_strides[0]\n",
    "    crop   = models[0].target_crops[0]\n",
    "\n",
    "    for (chrom, cstart, cend) in tqdm(all_windows, desc=\"Inference windows\"):\n",
    "        # 1) Формируем вход\n",
    "        input_start = max(0, cstart - context_len)\n",
    "        input_end   = min(chr_sizes[chrom], cend + context_len)\n",
    "\n",
    "        seq_1hot = process_sequence(fasta_index, chrom, input_start, input_end)\n",
    "        if seq_1hot is None or seq_1hot.shape[0] == 0:\n",
    "            continue\n",
    "\n",
    "        # 2) Предсказание\n",
    "        y_pred = predict_tracks(models, seq_1hot)  # [1, 1, L_out, C]\n",
    "        y_pred = y_pred[0,0,:,:]  # => [L_out, C]\n",
    "\n",
    "        L_out = y_pred.shape[0]\n",
    "\n",
    "        # 3) Определим, какой кусок реально соответствует [cstart, cend] \n",
    "        #    (учитывая crop)\n",
    "        offset_nt = stride * crop\n",
    "        out_start_nt = offset_nt\n",
    "        out_end_nt   = offset_nt + stride*(L_out - 2*crop)\n",
    "\n",
    "        center_start_in_input = cstart - input_start\n",
    "        center_end_in_input   = cend   - input_start\n",
    "\n",
    "        slice_start_nt = max(center_start_in_input, out_start_nt)\n",
    "        slice_end_nt   = min(center_end_in_input,   out_end_nt)\n",
    "        if slice_end_nt <= slice_start_nt:\n",
    "            continue\n",
    "\n",
    "        out_slice_start = int((slice_start_nt - out_start_nt)//stride)\n",
    "        out_slice_end   = int(np.ceil((slice_end_nt - out_start_nt)/stride))\n",
    "\n",
    "        # Границы\n",
    "        if out_slice_start < 0: \n",
    "            out_slice_start = 0\n",
    "        if out_slice_end > (L_out - 2*crop):\n",
    "            out_slice_end = L_out - 2*crop\n",
    "        if out_slice_end <= out_slice_start:\n",
    "            continue\n",
    "\n",
    "        out_slice_start_full = crop + out_slice_start\n",
    "        out_slice_end_full   = crop + out_slice_end\n",
    "\n",
    "        # 4) Выделяем нужную часть\n",
    "        center_pred = y_pred[out_slice_start_full : out_slice_end_full, :]  # [L_slice, C]\n",
    "        length_slice = center_pred.shape[0]\n",
    "\n",
    "        if length_slice <= 0:\n",
    "            continue\n",
    "\n",
    "        # 5) Для каждого канала => делаем inverse transform => пишем в bedGraph\n",
    "        #    Данные для transform (clip, clip_soft, scale, sum_stat) берём из filtered_df\n",
    "        #    (или targets_df) для данного канала, \n",
    "        #    indices => model slice => channel_ix\n",
    "        #    => row = filtered_df.iloc[...] ???\n",
    "\n",
    "        # Но у нас target_index (список глобальных ID) => channel_ix (0..C-1).\n",
    "        # => global_id = target_index[channel_ix]\n",
    "        # => row в targets_df.loc[global_id] => clip,clip_soft,scale,sum_stat\n",
    "\n",
    "        for channel_ix in range(center_pred.shape[1]):\n",
    "            global_id = target_index[channel_ix]\n",
    "            row = targets_df.loc[global_id]\n",
    "            clip_val      = row['clip']\n",
    "            clip_soft_val = row['clip_soft']\n",
    "            scale_val     = row['scale']\n",
    "            sum_stat_val  = row['sum_stat']\n",
    "\n",
    "            # 5a) обратная трансформация\n",
    "            values = inverse_transform(center_pred[:, channel_ix], clip_val, clip_soft_val, scale_val, sum_stat_val)\n",
    "\n",
    "            # 5b) Пишем\n",
    "            file_id = row['file_id']  # имя\n",
    "            file_path_bg = os.path.join(output_dir, f\"borzoi_rnaseq_{folds_str}_{file_id}.bedGraph\")\n",
    "\n",
    "            # Координаты\n",
    "            for i, val in enumerate(values):\n",
    "                pos_start = cstart + i*stride\n",
    "                pos_end   = pos_start + stride\n",
    "                if pos_end > cend:\n",
    "                    pos_end = cend\n",
    "                if pos_end <= pos_start:\n",
    "                    break\n",
    "                with open(file_path_bg, \"a\") as f_bg:\n",
    "                    f_bg.write(f\"{chrom}\\t{pos_start}\\t{pos_end}\\t{float(val)}\\n\")\n",
    "\n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"Инференс завершён за {elapsed:.2f} секунд.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2f2112a1-8aa0-42b0-8144-2ff3e941cdab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start inference...\n",
      "Начинаем инференс по 1785 окнам.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference windows:   7%|█████████▏                                                                                                                 | 133/1785 [10:05<2:05:19,  4.55s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStart inference...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mrun_inference\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_windows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDone. BedGraph files have been saved.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[25], line 93\u001b[0m, in \u001b[0;36mrun_inference\u001b[0;34m(all_windows, models)\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m pos_end \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m pos_start:\n\u001b[1;32m     92\u001b[0m                 \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m---> 93\u001b[0m             \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile_path_bg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43ma\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f_bg:\n\u001b[1;32m     94\u001b[0m                 f_bg\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mchrom\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mpos_start\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mpos_end\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mfloat\u001b[39m(val)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     96\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[0;32m/home/vsfishman/miniconda3/envs/borzoi/lib/python3.10/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/vsfishman/miniconda3/envs/borzoi/lib/python3.10/codecs.py:186\u001b[0m, in \u001b[0;36mIncrementalEncoder.__init__\u001b[0;34m(self, errors)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mIncrementalEncoder\u001b[39;00m(\u001b[38;5;28mobject\u001b[39m):\n\u001b[1;32m    181\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;124;03m    An IncrementalEncoder encodes an input in multiple steps. The input can\u001b[39;00m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;124;03m    be passed piece by piece to the encode() method. The IncrementalEncoder\u001b[39;00m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;124;03m    remembers the state of the encoding process between calls to encode().\u001b[39;00m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 186\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    187\u001b[0m \u001b[38;5;250m        \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;124;03m        Creates an IncrementalEncoder instance.\u001b[39;00m\n\u001b[1;32m    189\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;124;03m        for a list of possible values.\u001b[39;00m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;124;03m        \"\"\"\u001b[39;00m\n\u001b[1;32m    194\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merrors \u001b[38;5;241m=\u001b[39m errors\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"Start inference...\")\n",
    "run_inference(all_windows, models)\n",
    "print(\"Done. BedGraph files have been saved.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
